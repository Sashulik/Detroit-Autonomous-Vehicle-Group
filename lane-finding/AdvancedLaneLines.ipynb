{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "1. Apply a distortion correction to raw images.\n",
    "1. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "1. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "1. Detect lane pixels and fit to find the lane boundary.\n",
    "1. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "1. Warp the detected lane boundaries back onto the original image.\n",
    "1. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Author:* Brahm Windeler  \n",
    "*Date:* March 9, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOAL 1: Compute the camera calibration matrix and distortion coefficients given a set of chessboard images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0-0 IMPORT LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "\n",
    "from matplotlib.patches import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1-1 Read in the list of calibration image files\n",
    "\n",
    "cal_images = glob.glob('RaspiWideAngleCalibrationImages/cali*.jpg')\n",
    "#print (cal_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1-2 Accumulate the calibration points and show the results\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "plt.figure(figsize=(20,30))\n",
    "i = 1\n",
    "\n",
    "dst_test_images = glob.glob('test_images/*.jpg')\n",
    "test_img = cv2.imread(dst_test_images[0])\n",
    "\n",
    "for fname in cal_images:\n",
    "    \n",
    "    print (\"processing image {}\".format(i))\n",
    "\n",
    "    #img = mpimg.imread(fname)\n",
    "    ##print (\"img \",img.shape)\n",
    "    ##plt.imshow(img)\n",
    "    ##plt.show()\n",
    "    #padding = 500\n",
    "    #black = np.zeros((img.shape[0]+padding*2,img.shape[1]+padding*2,3),np.uint8)\n",
    "    ##print (\"black \", black.shape)\n",
    "    #black[padding:(img.shape[0]+padding),padding:(img.shape[1]+padding),:] = img\n",
    "    #img = black\n",
    "    ##plt.imshow(black)\n",
    "    ##plt.show()\n",
    "\n",
    "    width = int(test_img.shape[0])\n",
    "    height = int(test_img.shape[1])\n",
    "    \n",
    "    img = mpimg.imread(fname)\n",
    "    img_sm = cv2.resize(img, (height, width))\n",
    "    img = img_sm\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    altered = False\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        altered = True\n",
    "\n",
    "    # show all images, even those that didn't have 9x6 corners\n",
    "    ax = plt.subplot(7,3,i)\n",
    "    ax.imshow(img)\n",
    "    if (altered):\n",
    "        ax.set_title(\"9x6 FOUND\")\n",
    "    else:\n",
    "        ax.set_title(\"9x6 NOT FOUND\")\n",
    "    i += 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOAL 2: Apply a distortion correction to raw images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2-1 Define a wrapper around the calibration and undistort functions for\n",
    "#     undistorting an image.\n",
    "\n",
    "def cal_undistort(img):\n",
    "    '''\n",
    "    Undistorts an image given previously determined calibration points.\n",
    "    '''\n",
    "    global objpoints, imgpoints\n",
    "    \n",
    "    img_size = (img.shape[0], img.shape[1])\n",
    "    \n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "    #return cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    h,  w = img.shape[:2]\n",
    "    newCameraMtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "    mapx,mapy = cv2.initUndistortRectifyMap(mtx,dist,None,newCameraMtx,(w,h),5)\n",
    "    dst = cv2.remap(img,mapx,mapy,cv2.INTER_LINEAR)\n",
    "    \n",
    "    return dst\n",
    "    \n",
    "    print (\"dst.shape: \", dst.shape)\n",
    "    #x,y,w,h = roi\n",
    "    #x = 0\n",
    "    #y = 1694\n",
    "    #w = 250\n",
    "    #h = 250\n",
    "    #print (roi)\n",
    "    \n",
    "    x = 150\n",
    "    w = 850\n",
    "    y = 300\n",
    "    h = 450\n",
    "\n",
    "    dst = dst[y:y+h, x:x+w]\n",
    "    \n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_undistort_simple(img):\n",
    "    '''\n",
    "    Undistorts an image given previously determined calibration points.\n",
    "    '''\n",
    "    global objpoints, imgpoints\n",
    "    \n",
    "    img_size = (img.shape[0], img.shape[1])\n",
    "    \n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2-3 Read in test images provided with the project\n",
    "\n",
    "test_images = glob.glob('test_images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "for fname in test_images:\n",
    "    img = mpimg.imread(fname)\n",
    "    undistorted = cal_undistort(img)\n",
    "    mpimg.imsave(\"undistorted_image{}.jpg\".format(i), undistorted)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2-2 Demonstrate how the function undistorts the calibration images\n",
    "\n",
    "def demonstrate_image_undistort(imgs):\n",
    "    \n",
    "    for fname in imgs:\n",
    "        \n",
    "        # Read in the image and undistort it\n",
    "        \n",
    "        img = mpimg.imread(fname)\n",
    "        #print (\"img \",img.shape)\n",
    "        #plt.imshow(img)\n",
    "        #plt.show()\n",
    "        \n",
    "        #padding = 500\n",
    "        #black = np.zeros((img.shape[0]+padding*2,img.shape[1]+padding*2,3),np.uint8)\n",
    "        #print (\"black \", black.shape)\n",
    "        #black[padding:(img.shape[0]+padding),padding:(img.shape[1]+padding),:] = img\n",
    "        #img = black\n",
    "        \n",
    "        #img = mpimg.imread(fname)\n",
    "        undistorted = cal_undistort(img)\n",
    "\n",
    "        # Display the original and undistorted images\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "        f.tight_layout()\n",
    "        ax1.imshow(img)\n",
    "        ax1.set_title('Original Image', fontsize=50)\n",
    "        ax2.imshow(undistorted)\n",
    "        ax2.set_title('Undistorted Image', fontsize=50)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        plt.show()\n",
    "\n",
    "# UNCOMMENT TO RUN     \n",
    "#demonstrate_image_undistort([cal_images[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2-4 Demonstrate undistortion of some test images\n",
    "\n",
    "# UNCOMMENT TO RUN     \n",
    "demonstrate_image_undistort(test_images[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain images for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2-5 Define some generators for extracting frames from video clips.\n",
    "#     We'll need some consecutive images for testing previous fit lines.\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "import distutils.dir_util\n",
    "\n",
    "def frange(start, stop, step):\n",
    "    ''' Generator: Converts start, stop, and step parameters to a time value. '''\n",
    "    _idx = start\n",
    "    while _idx < stop:\n",
    "        yield _idx\n",
    "        _idx += step\n",
    "\n",
    "def extract_frames(name, start_time=0.0, interval=0.1, max_images=25):\n",
    "    ''' Generator: Extracts frames from a video clip and returns them one at a time. '''\n",
    "    if (name == \"\"):\n",
    "        return\n",
    "    clip = VideoFileClip(name + '.mp4')\n",
    "    for _clip_idx in frange(start_time, min([clip.end, start_time + max_images*interval]), interval):\n",
    "        yield clip.to_ImageClip(_clip_idx).img\n",
    "\n",
    "def save_frames_to_dir(name, t_start=0, t_end=None, fps=24):\n",
    "    ''' Extracts frames from a video clip and saves them to the filesystem. '''\n",
    "    if (name == \"\"):\n",
    "        return\n",
    "    clip = VideoFileClip(name + '.mp4').subclip(t_start, t_end)\n",
    "    distutils.dir_util.mkpath('{}/'.format(name))\n",
    "    return clip.write_images_sequence(\"{}/frame%03d.jpg\".format(name), fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2-6 Test the frame extracting generators by extracting a few frames.\n",
    "\n",
    "def demonstrate_extracting_video_frames():\n",
    "    for img in extract_frames('project_video', 0.0, 0.1, 3):\n",
    "        plt.figure()\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "# UNCOMMENT TO RUN\n",
    "#demonstrate_extracting_video_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2-7 Test the frame saving function\n",
    "\n",
    "# UNCOMMENT TO RUN\n",
    "#save_frames_to_dir('project_video', t_start=22.2, t_end=23.2, fps=24) # Problem spot 1\n",
    "#save_frames_to_dir('project_video', t_start=41.2, t_end=41.7, fps=24) # Problem spot 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2-8 Read in the extracted project video frames \n",
    "\n",
    "#pv_images = glob.glob('project_video/*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOAL 3: Apply a perspective transform to rectify binary image (\"birds-eye view\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3-1 Define a class to handle performing a birds-eye transform of the lane ahead.\n",
    "#     Also contains the src and dst reference points as well as methods for drawing\n",
    "#     reference boundaries on the transformed images.\n",
    "\n",
    "class BirdsEyeTransform():\n",
    "    ''' Class to hold the birds-eye transform information. Assumes 720 H x 1280 W \n",
    "        image from the center forward facing camera.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        # Reference source points for the perspective transform\n",
    "        #self.src = np.float32([(200,719), (580,460), (706,460), (1109,719)]) # Not symetric\n",
    "        ###self.src = np.float32([(200,719), (580,460), (699,460), (1079,719)])\n",
    "        #self.src = np.float32([(200,719), (595,450), (684,450), (1079,719)]) # Too blurry at top when warped?\n",
    "\n",
    "        #                          TL       TR          BR         BL\n",
    "        self.src = np.float32([(406,431), (754,431), (974,674), (186,674)])\n",
    "        \n",
    "        # Reference destination points for the perspective transform\n",
    "        ###self.dst = np.float32([(320,719), (320,0),   (960,0),    (960,719)])\n",
    "        self.dst = np.float32([(320,0),   (960,0),    (960,994), (320,994)])\n",
    "    \n",
    "        \n",
    "        # The transformation matrix for the perspective warp\n",
    "        self.M = cv2.getPerspectiveTransform(self.src, self.dst)\n",
    "        \n",
    "        # Inverse transformation matrix for the perspective warp\n",
    "        self.Minv = cv2.getPerspectiveTransform(self.dst, self.src)\n",
    "        \n",
    "        # Points defining the ROI from the src img\n",
    "        src_shape = (994, 1296)\n",
    "        img = np.ones(src_shape, dtype=np.uint8)*255\n",
    "        warped = cv2.warpPerspective(img, self.Minv, (img.shape[1], img.shape[0]))\n",
    "        src_img = np.rint(warped).astype(np.uint8)\n",
    "    \n",
    "        src_img_nonzeros = src_img.nonzero()\n",
    "        x_min = min(src_img_nonzeros[1])\n",
    "        x_max = max(src_img_nonzeros[1])\n",
    "        y_min = min(src_img_nonzeros[0])\n",
    "        y_max = max(src_img_nonzeros[0])\n",
    "            \n",
    "        poly = []\n",
    "        poly.append((x_min, y_max))\n",
    "        poly.append((x_min, min(src_img_nonzeros[0][src_img_nonzeros[1] == x_min])))\n",
    "        poly.append((min(src_img_nonzeros[1][src_img_nonzeros[0] == y_min]), y_min))\n",
    "        poly.append((max(src_img_nonzeros[1][src_img_nonzeros[0] == y_min]), y_min))\n",
    "        poly.append((x_max, min(src_img_nonzeros[0][src_img_nonzeros[1] == x_max])))\n",
    "        poly.append((x_max, y_max))\n",
    "\n",
    "        self.roi = np.float32(poly)\n",
    "        \n",
    "    def draw_src_on_img(self, img, color=(255,0,0), thickness=2):\n",
    "        ''' Takes an RGB image and draws the src points (trapezoid) directly on\n",
    "            the image.\n",
    "        '''\n",
    "        cv2.polylines(img, [self.src.astype(int)], True, color=color, thickness=thickness)\n",
    "        \n",
    "    def draw_dst_on_img(self, img, color=(255,0,0), thickness=2):\n",
    "        ''' Takes an RGB image and draws the dst points (square) directly on\n",
    "            the image.\n",
    "        '''\n",
    "        # Perspective transforms require float points, but polylines requires ints\n",
    "        cv2.polylines(img, [self.dst.astype(int)], True, color=color, thickness=thickness)\n",
    "\n",
    "    def draw_src_on_img_gray(self, img, intensity=255, thickness=2):\n",
    "        ''' Takes a grayscale image and draws the src points (trapezoid) directly on\n",
    "            the image.\n",
    "        '''\n",
    "        cv2.polylines(img, [self.src.astype(int)], True, color=intensity, thickness=thickness)\n",
    "        \n",
    "    def draw_dst_on_img_gray(self, img, intensity=255, thickness=2):\n",
    "        ''' Takes a grayscale image and draws the dst points (square) directly on\n",
    "            the image.\n",
    "        '''\n",
    "        # Perspective transforms require float points, but polylines requires ints\n",
    "        cv2.polylines(img, [self.dst.astype(int)], True, color=intensity, thickness=thickness)\n",
    "        \n",
    "    def warp(self, img):\n",
    "        ''' Performs the perspective warp from src to dst. Returns the result. '''\n",
    "\n",
    "        warped = cv2.warpPerspective(img, self.M, (img.shape[1], img.shape[0]))\n",
    "        \n",
    "        # Round floats produced by warp to ints, then convert to unsigned 8-bit\n",
    "        # https://carnd-forums.udacity.com/questions/38545026/black-images\n",
    "        return np.rint(warped).astype(np.uint8)\n",
    "    \n",
    "    def unwarp(self, img):\n",
    "        ''' Performs the perspective warp from dst back to src. Returns the result. '''\n",
    "        warped = cv2.warpPerspective(img, self.Minv, (img.shape[1], img.shape[0]))\n",
    "        return np.rint(warped).astype(np.uint8)\n",
    "    \n",
    "    def apply_cropping_mask(self, img):\n",
    "        \n",
    "        # get dimensions of mask\n",
    "        bottom_right_pt = self.src[2]\n",
    "        bottom_left_pt = self.src[3]\n",
    "        offset = 86\n",
    "        bottom_right_x = int(bottom_right_pt[0] + offset)\n",
    "        bottom_left_x = int(bottom_left_pt[0] - offset)\n",
    "\n",
    "        # apply mask\n",
    "        #img[:,0:bottom_left_x,:] = img[:,bottom_left_x:bottom_left_x+1,:]\n",
    "        #img[:,bottom_right_x:,:] = img[:,bottom_right_x:bottom_right_x+1,:]\n",
    "        img[:,0:bottom_left_x,:] = 0\n",
    "        img[:,bottom_right_x:,:] = 0\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3-2 Create an instance of the BirdsEyeTransform class.\n",
    "\n",
    "birdseye = BirdsEyeTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3-3 Visualize the birdseye transform on test images\n",
    "\n",
    "def demonstrate_birdseye_transform(imgs):\n",
    "\n",
    "    for fname in imgs:\n",
    "\n",
    "        img = mpimg.imread(fname)\n",
    "        undistorted = cal_undistort(img)\n",
    "        \n",
    "        # Pre-process the image by masking out stuff\n",
    "        undistorted_masked = birdseye.apply_cropping_mask(undistorted)\n",
    "        \n",
    "        undistorted_warped = birdseye.warp(undistorted_masked)\n",
    "\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 22))\n",
    "        f.tight_layout()\n",
    "\n",
    "        ax1.imshow(undistorted)\n",
    "        ax1.set_title('Undistorted', fontsize=30)\n",
    "        ax1.add_patch(Polygon(birdseye.src, True, edgecolor='#ff0000', fill=False))\n",
    "\n",
    "        ax2.imshow(undistorted_warped)\n",
    "        ax2.set_title('Undistorted -> Warped', fontsize=30)\n",
    "        ax2.add_patch(Polygon(birdseye.dst, True, edgecolor='#ff0000', fill=False))\n",
    "\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        plt.show()\n",
    "\n",
    "# UNCOMMENT TO RUN\n",
    "demonstrate_birdseye_transform(test_images[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3-4 Verify how much the center shifts for the birds-eye transform\n",
    "\n",
    "# Assuming the left and right sides of the src and dst are symetrical and\n",
    "# equidistant from the sides of the image, the center shouldn't shift\n",
    "# (This was a problem with my originally chosen points.)\n",
    "\n",
    "def demonstrate_center_shift():\n",
    "    \n",
    "    src_img = np.zeros((720, 1280), dtype=np.uint8)\n",
    "    \n",
    "    center_marker = np.int32([(src_img.shape[1]//2 - 1,0), (src_img.shape[1]//2 - 1,src_img.shape[0])])\n",
    "    print(\"center_marker\", center_marker)\n",
    "    cv2.polylines(src_img, [center_marker], False, 255, 1)\n",
    "    \n",
    "    dst_img = birdseye.warp(src_img)\n",
    "    \n",
    "    dst_bottom_nonzeros = dst_img[dst_img.shape[0]-1].nonzero()\n",
    "    print(\"dst_bottom_nonzeros\", dst_bottom_nonzeros)\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 12))\n",
    "    f.tight_layout()\n",
    "\n",
    "    birdseye.draw_src_on_img_gray(src_img, intensity=127, thickness=2)\n",
    "    ax1.imshow(src_img, cmap='gray')\n",
    "    \n",
    "    birdseye.draw_dst_on_img_gray(dst_img, intensity=127, thickness=2)\n",
    "    ax2.imshow(dst_img, cmap='gray')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# UNCOMMENT TO RUN\n",
    "demonstrate_center_shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3-5 Visualize how a birdseye transform looks when \"unwarped\" back to the \n",
    "#     original perspective.\n",
    "\n",
    "def demonstrate_birdseye_reverse_usage():\n",
    "    \n",
    "    # Create a blank white image that represents the result of a birdeye warp\n",
    "    dst_img = np.ones((720, 1280), dtype=np.uint8)*255\n",
    "    \n",
    "    # \"Unwarp\" the image to the aleged source\n",
    "    src_img = birdseye.unwarp(dst_img)\n",
    "\n",
    "    # Determine the bounding box of the non-zero values from the unwarped image\n",
    "    src_img_nonzeros = src_img.nonzero()\n",
    "    x_min = min(src_img_nonzeros[1])\n",
    "    x_max = max(src_img_nonzeros[1])\n",
    "    y_min = min(src_img_nonzeros[0])\n",
    "    y_max = max(src_img_nonzeros[0])\n",
    "    \n",
    "    #print(\"src_img_nonzeros\", src_img_nonzeros)\n",
    "    \n",
    "    print(\"{} {} {} {}\".format(x_min, x_max, y_min, y_max))\n",
    "\n",
    "    # Get the polygon points that define the \"unwarped\" birdseye view\n",
    "    poly = []\n",
    "    poly.append((x_min, y_max))\n",
    "    poly.append((x_min, min(src_img_nonzeros[0][src_img_nonzeros[1] == x_min])))\n",
    "    poly.append((min(src_img_nonzeros[1][src_img_nonzeros[0] == y_min]), y_min))\n",
    "    poly.append((max(src_img_nonzeros[1][src_img_nonzeros[0] == y_min]), y_min))\n",
    "    poly.append((x_max, min(src_img_nonzeros[0][src_img_nonzeros[1] == x_max])))\n",
    "    poly.append((x_max, y_max))\n",
    "    print(\"poly\", poly)\n",
    "    \n",
    "    # Display the results\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 12))\n",
    "    f.tight_layout()\n",
    "\n",
    "    # Draw the simulated birdseye\n",
    "    birdseye.draw_dst_on_img_gray(dst_img, intensity=127, thickness=2)\n",
    "    ax1.imshow(dst_img, cmap='gray')\n",
    "    \n",
    "    # Draw the simulated original source image with the birdseye src coords and\n",
    "    # the polygon defining how the original was unwarped\n",
    "    birdseye.draw_src_on_img_gray(src_img, intensity=127, thickness=2)\n",
    "    ax2.imshow(src_img, cmap='gray')\n",
    "    ax2.add_patch(Polygon(np.float32(poly), True, edgecolor='#ff0000', fill=False))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "# UNCOMMENT TO RUN\n",
    "#demonstrate_birdseye_reverse_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOAL 4: Use color transforms, gradients, etc., to create a thresholded binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4-1 Define a number of threshold filters that can be used to try to\n",
    "#     extract the lane lines\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    '''\n",
    "    Applies Sobel filter in the x or y direction, takes the absolute\n",
    "    value and applies the specified threshold.\n",
    "    '''\n",
    "    \n",
    "    # 1) Convert to grayscale if necessary\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "        \n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    \n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "    #    is > thresh_min and < thresh_max\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    \n",
    "    # 6) Return this mask as the binary_output image\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def grad_magnitude_thresh(img, sobel_kernel=3, thresh=(0, 255)):\n",
    "    '''\n",
    "    Applies a Sobel in the x and y directions, computes the magnitude\n",
    "    of the gradient, then applies the specified threshold\n",
    "    '''\n",
    "    \n",
    "    # 1) Convert to grayscale if necessary\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "    \n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # 3) Calculate the magnitude\n",
    "    abs_sobel = np.power(np.add(np.power(sobelx,2),np.power(sobely,2)), 0.5)\n",
    "    \n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    # 5) Create a binary mask where magnitude thresholds are met\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    \n",
    "    # 6) Return this mask as the binary_output image\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def grad_direction_thresh(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    '''\n",
    "    Applies a Sobel in the x and y directions, then computes the\n",
    "    direction of the gradient and applies the specified threshold.\n",
    "    '''\n",
    "    \n",
    "    # 1) Convert to grayscale if necessary\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "    \n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    \n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    dir_sobel = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    \n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    binary_output = np.zeros_like(dir_sobel)\n",
    "    binary_output[(dir_sobel >= thresh[0]) & (dir_sobel <= thresh[1])] = 1\n",
    "    \n",
    "    # 6) Return this mask as the binary_output image\n",
    "    return binary_output\n",
    "\n",
    "def color_thresh(img, cvt=cv2.COLOR_RGB2HLS, channel=2, thresh=(0,255)):\n",
    "    ''' Selects a single color channel and applies a min/max threshold\n",
    "        to the values, returning a binary mask for the pixels that meet\n",
    "        the specified thresholds.\n",
    "        By default, converts from RGB to HLS space and uses the Saturation\n",
    "        channel.\n",
    "    '''\n",
    "    \n",
    "    # 1) Convert to the specified colorspace\n",
    "    if cvt != False:\n",
    "        alt = cv2.cvtColor(img, cvt)\n",
    "    else:\n",
    "        alt = img\n",
    "    \n",
    "    # 2) Select the specified channel from the colorspace\n",
    "    single_channel = alt[:,:,channel]\n",
    "    \n",
    "    # 3) Create a binary mask where the channel thresholds are met\n",
    "    binary_output = np.zeros_like(single_channel)\n",
    "    binary_output[(single_channel >= thresh[0]) & (single_channel <= thresh[1])] = 1\n",
    "    \n",
    "    # 4) Return this mask as the binary_output image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4-2 Various functions that combine the gradient and color threshold outputs.\n",
    "#     The first two were strategies that were tested before ultimately\n",
    "#     finding the last to be the most robust.\n",
    "\n",
    "# Does not use magnitude or direction, as they seemed to be very noisy\n",
    "def combined_thresh_strategy1(img, grad_ksize=27, mag_ksize=27, dir_ksize=15,\n",
    "           gradx_thresh=(20, 80), \n",
    "           grady_thresh=(30, 80),\n",
    "           mag_thresh=(15, 175),\n",
    "           dir_thresh=(0.6, 1.2),\n",
    "           sat_thresh=(140, 255),\n",
    "           lum_thresh=(198, 255)):\n",
    "\n",
    "    '''\n",
    "    Returns a binary image where the 'on' pixels pass a combination \n",
    "    of the above filters using the following logic:\n",
    "    \n",
    "    ((GradX & GradY) | Sat | Lum)\n",
    "    Old: ((GradX & GradY) | (Mag & Dir) | Sat ) & Lum\n",
    "\n",
    "    '''\n",
    "    \n",
    "    gry = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(gry, orient='x', sobel_kernel=grad_ksize, thresh=gradx_thresh)\n",
    "    grady = abs_sobel_thresh(gry, orient='y', sobel_kernel=grad_ksize, thresh=grady_thresh)\n",
    "    #mag_binary = grad_magnitude_thresh(gry, sobel_kernel=mag_ksize, thresh=mag_thresh)\n",
    "    #dir_binary = grad_direction_thresh(gry, sobel_kernel=dir_ksize, thresh=dir_thresh)\n",
    "    sat_binary = color_thresh(hls, cvt=False, thresh=sat_thresh)\n",
    "    lum_binary = color_thresh(hls, cvt=False, channel=1, thresh=lum_thresh)\n",
    "\n",
    "    combined = np.zeros_like(sat_binary)\n",
    "    #combined[(((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1)) | (sat_binary == 1)) & (lum_binary == 1)] = 1\n",
    "    combined[(((gradx == 1) & (grady == 1)) | (sat_binary == 1)) | (lum_binary == 1)] = 1\n",
    "    \n",
    "    return combined\n",
    "\n",
    "# Adapted from\n",
    "# https://github.com/swirlingsand/self-driving-car-nanodegree-nd013/blob/master/p4-CarND-Advanced-Lane-Lines/methods/processImage.py\n",
    "def combined_thresh_strategy2(img, grad_ksize=27, mag_ksize=27, dir_ksize=15,\n",
    "           gradx_thresh=(10, 120), \n",
    "           grady_thresh=(10, 120),\n",
    "           mag_thresh=(10, 120),\n",
    "           dir_thresh=(0.7, 2.0),\n",
    "           sat_thresh=(120, 200)):\n",
    "    \n",
    "    gry = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(gry, orient='x', sobel_kernel=grad_ksize, thresh=gradx_thresh)\n",
    "    grady = abs_sobel_thresh(gry, orient='y', sobel_kernel=grad_ksize, thresh=grady_thresh)\n",
    "    mag_binary = grad_magnitude_thresh(gry, sobel_kernel=mag_ksize, thresh=mag_thresh)\n",
    "    dir_binary = grad_direction_thresh(gry, sobel_kernel=dir_ksize, thresh=dir_thresh)\n",
    "    sat_binary = color_thresh(hls, cvt=False, thresh=sat_thresh)\n",
    "\n",
    "    combined = np.zeros_like(sat_binary)\n",
    "    combined[( ((gradx == 1)      & (grady == 1))      | \n",
    "               ((mag_binary == 1) & (dir_binary == 0)) | \n",
    "               (sat_binary == 1)\n",
    "             )] = 1\n",
    "    \n",
    "    return combined\n",
    "\n",
    "# Ultimately chosen implementation. Uses slightly different gradient parameters than strategy2\n",
    "# and instead of using the S channel from the HLS color encoding, the Luminosity and \n",
    "# Saturation HLS channels are added and averaged. This counteracts dark shadows on the \n",
    "# road that would otherwise have high values in the S channel.\n",
    "# Additionally, the inverse Direction gradient is used as this \"lights\" up the lane lines\n",
    "# appropritely for post-birdseye-warped images.\n",
    "def combined_thresh(img, grad_ksize=27, mag_ksize=27, dir_ksize=15,\n",
    "           gradx_thresh=(30, 120), \n",
    "           grady_thresh=(30, 120),\n",
    "           mag_thresh=(30, 120),\n",
    "           dir_thresh=(0.7, 1.57),\n",
    "           lumsat_thresh=(145, 255)):\n",
    "\n",
    "    '''\n",
    "    Returns a binary image where the 'on' pixels pass a combination \n",
    "    of the above filters using the following logic:\n",
    "    \n",
    "    (GradX & GradY) | (Mag & Dir) | ((Lum+Sat)/2)\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Convert the RGB to useful formats\n",
    "    gry = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(gry, orient='x', sobel_kernel=grad_ksize, thresh=gradx_thresh)\n",
    "    grady = abs_sobel_thresh(gry, orient='y', sobel_kernel=grad_ksize, thresh=grady_thresh)\n",
    "    mag_binary = grad_magnitude_thresh(gry, sobel_kernel=mag_ksize, thresh=mag_thresh)\n",
    "    dir_binary = grad_direction_thresh(gry, sobel_kernel=dir_ksize, thresh=dir_thresh)\n",
    "\n",
    "    # Take the average of adding the L and S channels from the HLS encoding and then apply\n",
    "    # the appropriate thresholds\n",
    "    lumsat = (np.float32(hls[:,:,1]) + np.float32(hls[:,:,2]))//2\n",
    "    lumsat_binary = np.zeros_like(gradx)\n",
    "    lumsat_binary[(lumsat >= lumsat_thresh[0]) & (lumsat <= lumsat_thresh[1])] = 1\n",
    "\n",
    "    # Combine the results\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[(((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 0)) | (lumsat_binary == 1))] = 1\n",
    "\n",
    "    # Convert to unsigned int and return\n",
    "    return np.uint8(combined)\n",
    "\n",
    "def davg_thresh(img, lumsat_thresh=(100, 255)):\n",
    "    # Convert the RGB to useful formats\n",
    "    gry = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    # Take the average of adding the L and S channels from the HLS encoding and then apply\n",
    "    # the appropriate thresholds\n",
    "    lumsat = (np.float32(hls[:,:,1]) + np.float32(hls[:,:,2]))//2\n",
    "    lumsat_binary = np.zeros_like(gry)\n",
    "    lumsat_binary[(lumsat >= lumsat_thresh[0]) & (lumsat <= lumsat_thresh[1])] = 1\n",
    "\n",
    "    return np.uint8(lumsat_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4-3 Define some additional diagnostic functions\n",
    "#     Adapted from https://carnd-forums.udacity.com/questions/32706990/answers/38548228\n",
    "\n",
    "def normalized(img):\n",
    "    return np.uint8(255*img/np.max(np.absolute(img)))\n",
    "\n",
    "def to_RGB(img):\n",
    "    if img.ndim == 2:\n",
    "        img_normalized = normalized(img)\n",
    "        return np.dstack((img_normalized, img_normalized, img_normalized))\n",
    "    elif img.ndim == 3:\n",
    "        return img\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def update_diagScreen_cell(diagScreen, img, w, h, r, c, text=None, color=(255,0,0), thickness=2):\n",
    "    rgb = to_RGB(img)\n",
    "    if text is not None:\n",
    "        fontFace = cv2.FONT_HERSHEY_COMPLEX\n",
    "        fontScale = 2\n",
    "        offset = 20\n",
    "        textSize, _ = cv2.getTextSize(text, fontFace, fontScale, thickness)\n",
    "        cv2.putText(rgb, text, (offset, textSize[1] + offset), fontFace, fontScale, color, thickness)\n",
    "    diagScreen[r*h:(r+1)*h, c*w:(c+1)*w] = cv2.resize(rgb, (w, h), interpolation=cv2.INTER_AREA)\n",
    "    return diagScreen\n",
    "\n",
    "def compose_filter_diagScreen(diag1=None, diag2=None, diag3=None, \n",
    "                              diag4=None, diag5=None, diag6=None, \n",
    "                              diag7=None, diag8=None, diag9=None,\n",
    "                              diag10=None, diag11=None, diag12=None,\n",
    "                              diag13=None, diag14=None, diag15=None,\n",
    "                              title1=None, title2=None, title3=None, \n",
    "                              title4=None, title5=None, title6=None,\n",
    "                              title7=None, title8=None, title9=None,\n",
    "                              title10=None, title11=None, title12=None,\n",
    "                              title13=None, title14=None, title15=None):\n",
    "\n",
    "    width = 320\n",
    "    height = 240\n",
    "    \n",
    "    rows = 5\n",
    "    cols = 3\n",
    "    \n",
    "    # Initialize the output image.\n",
    "    diagScreen = np.zeros((height * rows, width * cols, 3), dtype=np.uint8)\n",
    "    \n",
    "    # top row\n",
    "    if diag1 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag1, width, height, r=0, c=0, text=title1)\n",
    "    if diag2 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag2, width, height, r=0, c=1, text=title2)\n",
    "    if diag3 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag3, width, height, r=0, c=2, text=title3)\n",
    "\n",
    "    if diag4 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag4, width, height, r=1, c=0, text=title4)\n",
    "    if diag5 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag5, width, height, r=1, c=1, text=title5)\n",
    "    if diag6 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag6, width, height, r=1, c=2, text=title6)\n",
    "\n",
    "    if diag7 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag7, width, height, r=2, c=0, text=title7)\n",
    "    if diag8 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag8, width, height, r=2, c=1, text=title8)\n",
    "    if diag9 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag9, width, height, r=2, c=2, text=title9)\n",
    "\n",
    "    if diag10 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag10, width, height, r=3, c=0, text=title10)\n",
    "    if diag11 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag11, width, height, r=3, c=1, text=title11)\n",
    "    if diag12 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag12, width, height, r=3, c=2, text=title12)\n",
    "\n",
    "    # bottom row\n",
    "    if diag13 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag13, width, height, r=4, c=0, text=title13)\n",
    "    if diag14 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag14, width, height, r=4, c=1, text=title14)\n",
    "    if diag15 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag15, width, height, r=4, c=2, text=title15)\n",
    "\n",
    "    return diagScreen\n",
    "\n",
    "def compose_2x3_screen(diag1=None, diag2=None, diag3=None, \n",
    "                       diag4=None, diag5=None, diag6=None, \n",
    "                       title1=None, title2=None, title3=None, \n",
    "                       title4=None, title5=None, title6=None, \n",
    "                       color=(255,0,0), thickness=2):\n",
    "\n",
    "    width = 320\n",
    "    height = 240\n",
    "    \n",
    "    rows = 2\n",
    "    cols = 3\n",
    "    \n",
    "    # Initialize the output image.\n",
    "    diagScreen = np.zeros((height * rows, width * cols, 3), dtype=np.uint8)\n",
    "    \n",
    "    if diag1 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag1, width, height, r=0, c=0, text=title1, color=color, thickness=thickness)\n",
    "    if diag2 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag2, width, height, r=0, c=1, text=title2, color=color, thickness=thickness)\n",
    "    if diag3 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag3, width, height, r=0, c=2, text=title3, color=color, thickness=thickness)\n",
    "\n",
    "    if diag4 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag4, width, height, r=1, c=0, text=title4, color=color, thickness=thickness)\n",
    "    if diag5 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag5, width, height, r=1, c=1, text=title5, color=color, thickness=thickness)\n",
    "    if diag6 is not None:\n",
    "        diagScreen = update_diagScreen_cell(diagScreen, diag6, width, height, r=1, c=2, text=title6, color=color, thickness=thickness)\n",
    "\n",
    "    return diagScreen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4-4 Demonstrate the gradient threshold filters\n",
    "\n",
    "def demonstrate_gradient_threshold_comparison(fname, \n",
    "                                    grad_ksize=27, mag_ksize=27, dir_ksize=15,\n",
    "                                    gradx_min=30, gradx_max=120, \n",
    "                                    grady_min=30, grady_max=120,\n",
    "                                    mag_min=25, mag_max=120,\n",
    "                                    dir_min=0.7, dir_max=np.pi/2):\n",
    "    img = mpimg.imread(fname)\n",
    "    img = cal_undistort(img)\n",
    "    \n",
    "    masked = birdseye.apply_cropping_mask(img)   \n",
    "    img = birdseye.warp(masked)\n",
    "    \n",
    "    gry = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gry_rgb = cv2.cvtColor(gry, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    gradx = abs_sobel_thresh(gry, orient='x', sobel_kernel=grad_ksize, thresh=(gradx_min, gradx_max))\n",
    "    grady = abs_sobel_thresh(gry, orient='y', sobel_kernel=grad_ksize, thresh=(grady_min, grady_max))\n",
    "    mag_binary = grad_magnitude_thresh(gry, sobel_kernel=mag_ksize, thresh=(mag_min, mag_max))\n",
    "    dir_binary = grad_direction_thresh(gry, sobel_kernel=dir_ksize, thresh=(dir_min, dir_max))\n",
    "    \n",
    "    screen = compose_2x3_screen(diag1=img, diag2=gradx, diag3=grady, \n",
    "                       diag4=gry_rgb, diag5=mag_binary, diag6=dir_binary, \n",
    "                       title1=\"Original\", title2=\"Sobel X\", title3=\"Sobel Y\", \n",
    "                       title4=\"Grayscale\", title5=\"Magnitude\", title6=\"Direction\")\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(screen)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "# UNCOMMENT TO RUN\n",
    "demonstrate_gradient_threshold_comparison(test_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4-5 Demonstrate the HSV and HLS color channels\n",
    "\n",
    "def demonstrate_hsv_hls_color_channels(fname):\n",
    "    \n",
    "    img = mpimg.imread(fname)\n",
    "    img = cal_undistort(img)\n",
    "\n",
    "    masked = birdseye.apply_cropping_mask(img)   \n",
    "    img = birdseye.warp(masked)\n",
    "\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    hsv0 = cv2.cvtColor(hsv[:,:,0], cv2.COLOR_GRAY2RGB)\n",
    "    hsv1 = cv2.cvtColor(hsv[:,:,1], cv2.COLOR_GRAY2RGB)\n",
    "    hsv2 = cv2.cvtColor(hsv[:,:,2], cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    hls0 = cv2.cvtColor(hls[:,:,0], cv2.COLOR_GRAY2RGB)\n",
    "    hls1 = cv2.cvtColor(hls[:,:,1], cv2.COLOR_GRAY2RGB)\n",
    "    hls2 = cv2.cvtColor(hls[:,:,2], cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    screen = compose_2x3_screen(diag1=hsv0, diag2=hsv1, diag3=hsv2, \n",
    "                              diag4=hls0, diag5=hls1, diag6=hls2, \n",
    "                              title1=\"HSV H\", title2=\"HSV S\", title3=\"HSV V\", \n",
    "                              title4=\"HLS H\", title5=\"HLS L\", title6=\"HLS S\")\n",
    "\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(screen)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "# UNCOMMENT TO RUN\n",
    "demonstrate_hsv_hls_color_channels(test_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4-6 Demonstrate the HSV and HLS color channels\n",
    "\n",
    "def demonstrate_hsv_hls_color_channel_adding(fname):\n",
    "    \n",
    "    img = mpimg.imread(fname)\n",
    "    img = cal_undistort(img)\n",
    "\n",
    "    masked = birdseye.apply_cropping_mask(img)   \n",
    "    img = birdseye.warp(masked)\n",
    "    \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    hsv1 = cv2.cvtColor(hsv[:,:,1], cv2.COLOR_GRAY2RGB)\n",
    "    hsv2 = cv2.cvtColor(hsv[:,:,2], cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    hls1 = cv2.cvtColor(hls[:,:,1], cv2.COLOR_GRAY2RGB)\n",
    "    hls2 = cv2.cvtColor(hls[:,:,2], cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    satval = cv2.cvtColor(np.uint8((np.float32(hsv[:,:,1]) + np.float32(hsv[:,:,2]))//2), cv2.COLOR_GRAY2RGB)\n",
    "    lumsat = cv2.cvtColor(np.uint8((np.float32(hls[:,:,1]) + np.float32(hls[:,:,2]))//2), cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    screen = compose_2x3_screen(diag1=hsv1, diag2=hsv2, diag3=satval, \n",
    "                              diag4=hls1, diag5=hls2, diag6=lumsat, \n",
    "                              title1=\"HSV S\", title2=\"HSV V\", title3=\"HSV (S+V)/2\", \n",
    "                              title4=\"HLS L\", title5=\"HLS S\", title6=\"HLS (L+S)/2\")\n",
    "\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(screen)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "# UNCOMMENT TO RUN\n",
    "demonstrate_hsv_hls_color_channel_adding(test_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4-7 Visualize the combination of filters on a sample image\n",
    "#     to allow us to determing good threshold values.\n",
    "\n",
    "# OLD\n",
    "def update_demo_basic(imgs=[], grad_ksize=3, mag_ksize=3, dir_ksize=3, \n",
    "           gradx_min=0, gradx_max=255, \n",
    "           grady_min=0, grady_max=255,\n",
    "           mag_min=0, mag_max=255,\n",
    "           dir_min=0, dir_max=np.pi/2,\n",
    "           sat_min=0, sat_max=255,\n",
    "           lum_min=0, lum_max=255,\n",
    "           lumsat_min=0, lumsat_max=255):\n",
    "\n",
    "    if (len(imgs) == 0):\n",
    "        print(\"Must specifiy array of image files.\")\n",
    "        return\n",
    "    \n",
    "    img = mpimg.imread(imgs)\n",
    "    img = cal_undistort(img)\n",
    "    \n",
    "    combined = combined_thresh_strat2(img, grad_ksize, mag_ksize, dir_ksize,\n",
    "           gradx_thresh=(gradx_min, gradx_max), \n",
    "           grady_thresh=(grady_min, grady_max),\n",
    "           mag_thresh=(mag_min, mag_max),\n",
    "           dir_thresh=(dir_min, dir_max),\n",
    "           sat_thresh=(sat_min, sat_max),\n",
    "           lum_thresh=(lum_min, lum_max))\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original ({})'.format(test_images[idx]), fontsize=50)\n",
    "    ax2.imshow(combined, cmap='gray')\n",
    "    ax2.set_title('Combined Filter', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    plt.show()\n",
    "\n",
    "# A comprehensive selection of parameters\n",
    "def update_demo_thorough(imgs=[], do_warp=False,\n",
    "           grad_ksize=3, mag_ksize=3, dir_ksize=3,\n",
    "           gradx_min=0, gradx_max=255, \n",
    "           grady_min=0, grady_max=255,\n",
    "           mag_min=0, mag_max=255,\n",
    "           dir_min=0, dir_max=np.pi/2,\n",
    "           sat_min=0, sat_max=255,\n",
    "           lum_min=0, lum_max=255,\n",
    "           lumsat_min=0, lumsat_max=255):\n",
    "\n",
    "    if (len(imgs) == 0):\n",
    "        print(\"Must specifiy array of image files.\")\n",
    "        return\n",
    "    \n",
    "    img = mpimg.imread(imgs)\n",
    "    img = cal_undistort(img)\n",
    "    \n",
    "    if (do_warp):\n",
    "        img = birdseye.apply_cropping_mask(img)\n",
    "        img = birdseye.warp(img)\n",
    "    \n",
    "    gry = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(gry, orient='x', sobel_kernel=grad_ksize, thresh=(gradx_min, gradx_max))\n",
    "    grady = abs_sobel_thresh(gry, orient='y', sobel_kernel=grad_ksize, thresh=(grady_min, grady_max))\n",
    "    mag_binary = grad_magnitude_thresh(gry, sobel_kernel=mag_ksize, thresh=(mag_min, mag_max))\n",
    "    dir_binary = grad_direction_thresh(gry, sobel_kernel=dir_ksize, thresh=(dir_min, dir_max))\n",
    "    inv_dir_binary = np.zeros_like(dir_binary)\n",
    "    inv_dir_binary[dir_binary == 0] = 1\n",
    "    sat_binary = color_thresh(hls, cvt=False, thresh=(sat_min, sat_max))\n",
    "    lum_binary = color_thresh(hls, cvt=False, channel=1, thresh=(lum_min, lum_max))\n",
    "\n",
    "    # Create combined images for some of these\n",
    "    blank = np.zeros_like(gry).astype(np.uint8)\n",
    "    grad = np.dstack((blank, gradx & grady, blank))*255\n",
    "    \n",
    "    if (do_warp):\n",
    "        magdir = np.dstack((blank, mag_binary.astype(np.uint8) & inv_dir_binary.astype(np.uint8), blank))*255\n",
    "    else:\n",
    "        magdir = np.dstack((blank, mag_binary.astype(np.uint8) & dir_binary.astype(np.uint8), blank))*255\n",
    "        \n",
    "    sat = cv2.cvtColor(hls[:,:,2], cv2.COLOR_GRAY2RGB)\n",
    "    lum = cv2.cvtColor(hls[:,:,1], cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    lumsat = (np.float32(hls[:,:,1]) + np.float32(hls[:,:,2]))//2\n",
    "    lumsat_binary = np.zeros_like(lumsat)\n",
    "    lumsat_binary[(lumsat >= lumsat_min) & (lumsat <= lumsat_max)] = 1\n",
    "\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    if (do_warp):\n",
    "        combined[(((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (inv_dir_binary == 1)) | (lumsat_binary == 1))] = 1\n",
    "        dir_img = inv_dir_binary\n",
    "    else:\n",
    "        combined[(((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1)) | (lumsat_binary == 1))] = 1\n",
    "        dir_img = dir_binary\n",
    "        \n",
    "    screen = compose_filter_diagScreen(diag1=gradx, title1=\"Sobel X\",\n",
    "                                       diag2=grad, title2=\"Sobel X & Y\",\n",
    "                                       diag3=grady, title3=\"Sobel Y\",\n",
    "                                       diag4=sat, title4=\"Saturation Orig\",\n",
    "                                       diag5=lumsat, title5=\"Lum+Sat Orig\",\n",
    "                                       diag6=lum, title6=\"Luminosity Orig\",\n",
    "                                       diag7=sat_binary, title7=\"Saturation Thresh\",\n",
    "                                       diag8=lumsat_binary, title8=\"Lum+Sat Thresh\",\n",
    "                                       diag9=lum_binary, title9=\"Luminosity Thresh\",\n",
    "                                       diag10=mag_binary, title10=\"Magnitude\",\n",
    "                                       diag11=magdir, title11=\"Mag & Dir\",\n",
    "                                       diag12=dir_img, title12=\"Direction\",\n",
    "                                       diag13=img, title13=\"Original\",\n",
    "                                       diag14=combined, title14=\"Used Combined\",)\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(screen)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def demonstrate_filter_parameters(images):\n",
    "    #imgidx_slider = widgets.IntSlider(min=0, max=len(images)-1, step=1, value=0)\n",
    "    \n",
    "    warp_toggle = widgets.widget_bool.ToggleButton(value=True)\n",
    "\n",
    "    # Sobel kernel size - odd number - larger = smoother gradient measurements - max 31\n",
    "    grad_ksize_slider = widgets.IntSlider(min=3, max=31, step=2, value=27) #3\n",
    "    mag_ksize_slider = widgets.IntSlider(min=3, max=31, step=2, value=27)  #3\n",
    "    dir_ksize_slider = widgets.IntSlider(min=3, max=31, step=2, value=15)  #3\n",
    "\n",
    "    gradx_min_slider = widgets.IntSlider(min=0, max=255, step=1, value=30)  #20\n",
    "    gradx_max_slider = widgets.IntSlider(min=0, max=255, step=1, value=120)  #80\n",
    "\n",
    "    grady_min_slider = widgets.IntSlider(min=0, max=255, step=1, value=30)  #30\n",
    "    grady_max_slider = widgets.IntSlider(min=0, max=255, step=1, value=120)  #80\n",
    "\n",
    "    mag_min_slider = widgets.IntSlider(min=0, max=255, step=1, value=25)  #15\n",
    "    mag_max_slider = widgets.IntSlider(min=0, max=255, step=1, value=120)  #175\n",
    "    \n",
    "    dir_min_slider = widgets.FloatSlider(min=0, max=np.pi/2, step=0.05, value=0.7) #0.6\n",
    "    dir_max_slider = widgets.FloatSlider(min=0, max=np.pi/2, step=0.05, value=1.57) #1.2\n",
    "\n",
    "    sat_min_slider = widgets.IntSlider(min=0, max=255, step=1, value=120) #140\n",
    "    sat_max_slider = widgets.IntSlider(min=0, max=255, step=1, value=200) #255\n",
    "\n",
    "    lum_min_slider = widgets.IntSlider(min=0, max=255, step=1, value=160) #198\n",
    "    lum_max_slider = widgets.IntSlider(min=0, max=255, step=1, value=255) #255\n",
    "\n",
    "    lumsat_min_slider = widgets.IntSlider(min=0, max=255, step=1, value=145)\n",
    "    lumsat_max_slider = widgets.IntSlider(min=0, max=255, step=1, value=255)\n",
    "    \n",
    "    w=widgets.interactive(update_demo_thorough, imgs=images, do_warp=warp_toggle,\n",
    "                          grad_ksize=grad_ksize_slider, mag_ksize=mag_ksize_slider, dir_ksize=dir_ksize_slider,\n",
    "                          gradx_min=gradx_min_slider, gradx_max=gradx_max_slider, \n",
    "                          grady_min=grady_min_slider, grady_max=grady_max_slider,\n",
    "                          mag_min=mag_min_slider, mag_max=mag_max_slider,\n",
    "                          dir_min=dir_min_slider, dir_max=dir_max_slider,\n",
    "                          sat_min=sat_min_slider, sat_max=sat_max_slider,\n",
    "                          lum_min=lum_min_slider, lum_max=lum_max_slider,\n",
    "                          lumsat_min=lumsat_min_slider, lumsat_max=lumsat_max_slider)\n",
    "    display(w)\n",
    "\n",
    "# UNCOMMENT TO RUN\n",
    "demonstrate_filter_parameters(test_images)\n",
    "#demonstrate_filter_parameters(test_images + pv_images)\n",
    "#demonstrate_filter_parameters(pv_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4-8 INCOMPLETE EXPERIMENT\n",
    "def demonstrate_adding_img_channels(fname):\n",
    "    \n",
    "    img = mpimg.imread(fname)\n",
    "    img = cal_undistort(img)\n",
    "    \n",
    "    #img = birdseye.warp(img)\n",
    "    \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)  \n",
    "    h1, s1, v1 = cv2.split(hsv)\n",
    "    \n",
    "    #st = 180\n",
    "    #vt = 198\n",
    "    #s1[s1 < st] = 0\n",
    "    #s1[s1 > st] = 255\n",
    "    #v1[v1 < vt] = 0\n",
    "    #v1[v1 > vt] = 255\n",
    "    sv = (np.float32(s1) + np.float32(v1))//2\n",
    "    sv[sv < 90] = 0\n",
    "    svrgb = cv2.cvtColor(np.uint8(sv), cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    h2, l2, s2 = cv2.split(hls)\n",
    "    ls = (np.float32(l2) + np.float32(s2))//2\n",
    "    ls[ls < 95] = 0\n",
    "    lsrgb = cv2.cvtColor(np.uint8(ls), cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    svls = (np.float32(l2) + np.float32(s2))//2\n",
    "    svls[svls < 128] = 0\n",
    "    svls4 = (np.float32(s1) + np.float32(v1) + np.float32(l2) + np.float32(s2))//4\n",
    "    svls4[svls4 < 133] = 0\n",
    "    svls4[svls4 > 132] = 255\n",
    "    \n",
    "    svlsrgb = cv2.cvtColor(np.uint8(svls), cv2.COLOR_GRAY2RGB)\n",
    "    svls4rgb = cv2.cvtColor(np.uint8(svls4), cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    ksize=3\n",
    "    gradx_thresh=(20, 80)\n",
    "    grady_thresh=(30, 170)\n",
    "    mag_thresh=(15, 175)\n",
    "    dir_thresh=(0.6, 1.2)\n",
    "    #sat_thresh=(140, 255)\n",
    "    #lum_thresh=(198, 255)\n",
    "            \n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(s1, orient='x', sobel_kernel=ksize, thresh=gradx_thresh)\n",
    "    grady = abs_sobel_thresh(s1, orient='y', sobel_kernel=ksize, thresh=grady_thresh)\n",
    "    mag_binary = grad_magnitude_thresh(s1, sobel_kernel=ksize, thresh=mag_thresh)\n",
    "    dir_binary = grad_direction_thresh(s1, sobel_kernel=ksize, thresh=dir_thresh)\n",
    "    \n",
    "    grad = (np.float32(gradx) + np.float32(grady))//2\n",
    "    magdir = (np.float32(mag_binary) + np.float32(dir_binary))//2\n",
    "    \n",
    "    #biggie = (np.float32(s1) + np.float32(v1) + np.float32(l2) + np.float32(s2) + \n",
    "    #          np.float32(gradx) + np.float32(grady) + np.float32(mag_binary) + np.float32(dir_binary))//8\n",
    "    #biggie[biggie < 70] = 0\n",
    "    #biggie[biggie > 69] = 255\n",
    "    biggie = (np.float32(sv) + np.float32(ls) + \n",
    "              np.float32(gradx) + np.float32(grady) + np.float32(mag_binary) + np.float32(dir_binary))//6\n",
    "    biggie[biggie < 40] = 0\n",
    "    biggie[biggie > 39] = 255\n",
    "\n",
    "    biggiergb = cv2.cvtColor(np.uint8(biggie), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    f, axes = plt.subplots(5,3, figsize=(20,20))\n",
    "    \n",
    "    axes[0][0].imshow(s1, cmap='gray')\n",
    "    axes[0][1].imshow(v1, cmap='gray')\n",
    "    axes[0][2].imshow(svrgb)\n",
    "\n",
    "    axes[1][0].imshow(l2, cmap='gray')\n",
    "    axes[1][1].imshow(s2, cmap='gray')\n",
    "    axes[1][2].imshow(lsrgb)\n",
    "    \n",
    "    axes[2][0].imshow(img)\n",
    "    axes[2][1].imshow(svls4rgb)\n",
    "    axes[2][2].imshow(biggiergb)\n",
    "\n",
    "    axes[3][0].imshow(gradx, cmap='gray')\n",
    "    axes[3][1].imshow(grady, cmap='gray')\n",
    "    axes[3][2].imshow(grad, cmap='gray')\n",
    "\n",
    "    axes[4][0].imshow(mag_binary, cmap='gray')\n",
    "    axes[4][1].imshow(dir_binary, cmap='gray')\n",
    "    axes[4][2].imshow(magdir, cmap='gray')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# UNCOMMENT TO RUN\n",
    "#demonstrate_adding_img_channels(test_images[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4-9 INCOMPLETE EXPERIMENT\n",
    "def demonstrate_adding_img_channels_alt(fname, warp_first=True):\n",
    "    \n",
    "    img = mpimg.imread(fname)\n",
    "    img = cal_undistort(img)\n",
    "    \n",
    "    if (warp_first):\n",
    "        img = birdseye.warp(img)\n",
    "    \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)  \n",
    "    h1, s1, v1 = cv2.split(hsv)\n",
    "\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    h2, l2, s2 = cv2.split(hls)\n",
    "\n",
    "    s1o = np.copy(s1)\n",
    "    s1t = 127\n",
    "    s1[s1<s1t] = 0\n",
    "    s1[s1>s1t-1] = 255\n",
    "    \n",
    "    s2o = np.copy(s2)\n",
    "    s2t = 100\n",
    "    s2[s2<s2t] = 0\n",
    "    s2[s2>s2t-1] = 255\n",
    "\n",
    "    v1o = np.copy(v1)\n",
    "    v1t = 200\n",
    "    v1[v1<v1t] = 0\n",
    "    v1[v1>v1t-1] = 255    \n",
    "\n",
    "    l2o = np.copy(l2)\n",
    "    l2t = 200\n",
    "    l2[l2<l2t] = 0\n",
    "    l2[l2>l2t-1] = 255\n",
    "\n",
    "    sv = (np.float32(s1o) + np.float32(v1o))//2\n",
    "    svo = np.copy(sv)\n",
    "    svt = 135\n",
    "    sv[sv < svt] = 0\n",
    "    sv[sv > svt-1] = 255\n",
    "    svo_rgb = cv2.cvtColor(np.uint8(svo), cv2.COLOR_GRAY2RGB)\n",
    "    sv_rgb = cv2.cvtColor(np.uint8(sv), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    ls = (np.float32(l2o) + np.float32(s2o))//2\n",
    "    lso = np.copy(ls)\n",
    "    lst = 125\n",
    "    ls[ls < lst] = 0\n",
    "    ls[ls > lst-1] = 255\n",
    "    lso_rgb = cv2.cvtColor(np.uint8(lso), cv2.COLOR_GRAY2RGB)\n",
    "    ls_rgb = cv2.cvtColor(np.uint8(ls), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    comb = (np.float32(s1) + np.float32(v1) + np.float32(l2) + np.float32(s2) + np.float32(sv) + np.float32(ls))//6\n",
    "    combt = 127\n",
    "    comb[comb<combt] = 0\n",
    "    comb[comb>combt-1] = 255\n",
    "    comb_rgb = cv2.cvtColor(np.uint8(comb), cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    if (not warp_first):\n",
    "        comb_rgb = birdseye.warp(comb_rgb)\n",
    "     \n",
    "    f, axes = plt.subplots(7,2, figsize=(20,40))\n",
    "    \n",
    "    axes[0][0].imshow(img)\n",
    "    axes[0][0].set_title(\"Original\")\n",
    "    axes[0][1].imshow(comb_rgb)\n",
    "    axes[0][1].set_title(\"Combined\")\n",
    "\n",
    "    axes[1][0].imshow(s1o, cmap='gray')\n",
    "    axes[1][0].set_title(\"HSV Sat\")\n",
    "    axes[1][1].imshow(s1, cmap='gray')\n",
    "    axes[1][1].set_title(\"HSV Sat Thresh\")\n",
    "\n",
    "    axes[2][0].imshow(s2o, cmap='gray')\n",
    "    axes[2][0].set_title(\"HLS Sat\")\n",
    "    axes[2][1].imshow(s2, cmap='gray')\n",
    "    axes[2][1].set_title(\"HLS Sat Thresh\")\n",
    "    \n",
    "    axes[3][0].imshow(v1o, cmap='gray')\n",
    "    axes[3][0].set_title(\"HSV Val\")\n",
    "    axes[3][1].imshow(v1, cmap='gray')\n",
    "    axes[3][1].set_title(\"HSV Val Thresh\")\n",
    "\n",
    "    axes[4][0].imshow(l2o, cmap='gray')\n",
    "    axes[4][0].set_title(\"HLS Lum\")\n",
    "    axes[4][1].imshow(l2, cmap='gray')\n",
    "    axes[4][1].set_title(\"HLS Lum Thresh\")\n",
    "\n",
    "    axes[5][0].imshow(svo_rgb)\n",
    "    axes[5][0].set_title(\"HSV Sat+Val\")\n",
    "    axes[5][1].imshow(sv_rgb)\n",
    "    axes[5][1].set_title(\"HSV Sat+Val Thresh\")\n",
    "\n",
    "    axes[6][0].imshow(lso_rgb)\n",
    "    axes[6][0].set_title(\"HLS Lum+Sat\")\n",
    "    axes[6][1].imshow(ls_rgb)\n",
    "    axes[6][1].set_title(\"HLS Lum+Sat Thresh\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# UNCOMMENT TO RUN\n",
    "#demonstrate_adding_img_channels_alt(test_images[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4-10 Visualize the birdseye transform on test images\n",
    "\n",
    "# Performing the warp first and then threshold results in better combined output\n",
    "# than threshold first then warp.\n",
    "\n",
    "def demonstrate_birdseye_transform_with_thresholds(imgs):\n",
    "\n",
    "    for fname in imgs:\n",
    "\n",
    "        img = mpimg.imread(fname)\n",
    "        undistorted = cal_undistort(img)\n",
    "        undistorted_warped = birdseye.warp(undistorted)\n",
    "\n",
    "        binary = combined_thresh(undistorted)\n",
    "        binary_warped = birdseye.warp(binary)\n",
    "\n",
    "        undistorted_warped_binary = combined_thresh(undistorted_warped)\n",
    "\n",
    "        f, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(20, 22))\n",
    "        f.tight_layout()\n",
    "\n",
    "        ax1.imshow(undistorted)\n",
    "        ax1.set_title('Undistorted', fontsize=30)\n",
    "        ax1.add_patch(Polygon(birdseye.src, True, edgecolor='#ff0000', fill=False))\n",
    "\n",
    "        ax2.imshow(undistorted_warped)\n",
    "        ax2.set_title('Undistorted -> Warped', fontsize=30)\n",
    "        ax2.add_patch(Polygon(birdseye.dst, True, edgecolor='#ff0000', fill=False))\n",
    "\n",
    "        ax3.imshow(binary, cmap='gray')\n",
    "        ax3.set_title('Undistorted -> Thresholded', fontsize=30)\n",
    "        ax3.add_patch(Polygon(birdseye.src, True, edgecolor='#ff0000', fill=False))\n",
    "\n",
    "        ax4.imshow(binary_warped, cmap='gray')\n",
    "        ax4.set_title('Thresholded -> Warped', fontsize=30)\n",
    "        ax4.add_patch(Polygon(birdseye.dst, True, edgecolor='#ff0000', fill=False))\n",
    "\n",
    "        f.delaxes(ax5)\n",
    "\n",
    "        ax6.imshow(undistorted_warped_binary, cmap='gray')\n",
    "        ax6.set_title('Undistorted -> Warped -> Thresholded', fontsize=30)\n",
    "        ax6.add_patch(Polygon(birdseye.dst, True, edgecolor='#ff0000', fill=False))\n",
    "\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        plt.show()\n",
    "\n",
    "# UNCOMMENT TO RUN\n",
    "demonstrate_birdseye_transform_with_thresholds([test_images[0], test_images[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4-11 Define a convenience method for performing the undistort, birdseye warp, \n",
    "#      and threshold functions all in one fell (fowl?) swoop.\n",
    "\n",
    "def get_birdseye_binary_warped(img, undistort=True):\n",
    "    ''' Convenience method.\n",
    "    Undistorts an image (using previously determined globally accessible\n",
    "    calibration data), warps it to the birdseye view, converting it to a uint8 \n",
    "    after warping, then applying the combined threshold.\n",
    "    Optionally: skip the undistort step.\n",
    "    '''\n",
    "    global birdseye, objpoints, imgpoints\n",
    "    \n",
    "    if (undistort):\n",
    "        undistorted = cal_undistort(img)\n",
    "    else:\n",
    "        undistorted = img\n",
    "    \n",
    "    # Apply the thresholds\n",
    "    #binary = combined_thresh(undistorted)\n",
    "    # Warp to birds-eye view\n",
    "    #return birdseye.warp(binary)\n",
    "\n",
    "    # Warp to birds-eye view\n",
    "    masked = birdseye.apply_cropping_mask(undistorted)\n",
    "    warped = birdseye.warp(masked)\n",
    "    \n",
    "    # Apply the thresholds\n",
    "    return davg_thresh(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4-12 Demonstrate the direction gradient threshold on an image versus\n",
    "#      the birdseye warped version of the image.\n",
    "\n",
    "def demonstrate_direction_gradient_comparison(fname, dir_ksize=15, dir_min=0.7, dir_max=np.pi/2):\n",
    "    \n",
    "    img = mpimg.imread(fname)\n",
    "    img = cal_undistort(img)\n",
    "    \n",
    "    # Grayscale\n",
    "    gry = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gry_rgb = cv2.cvtColor(gry, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Dir of Grayscale\n",
    "    dir_binary = grad_direction_thresh(gry, sobel_kernel=dir_ksize, thresh=(dir_min, dir_max))\n",
    "    \n",
    "    # Inverted Dir of Grayscale\n",
    "    inv_dir_binary = np.zeros_like(dir_binary)\n",
    "    inv_dir_binary[dir_binary == 0] = 1\n",
    "    \n",
    "    # Warped Grayscale\n",
    "    warped = birdseye.warp(img)\n",
    "    warped_gry = cv2.cvtColor(warped, cv2.COLOR_RGB2GRAY)\n",
    "    warped_gry_rgb = cv2.cvtColor(warped_gry, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # Dir of Warped Grayscale\n",
    "    warped_dir_binary = grad_direction_thresh(warped_gry, sobel_kernel=dir_ksize, thresh=(dir_min, dir_max))\n",
    "    \n",
    "    # Inverted Dir of Warped Grayscale\n",
    "    inv_warped_dir_binary = np.zeros_like(warped_dir_binary)\n",
    "    inv_warped_dir_binary[warped_dir_binary == 0] = 1    \n",
    "    \n",
    "    screen = compose_2x3_screen(diag1=gry_rgb, diag2=dir_binary, diag3=inv_dir_binary, \n",
    "                       diag4=warped_gry_rgb, diag5=warped_dir_binary, diag6=inv_warped_dir_binary, \n",
    "                       title1=\"Grayscale\", title2=\"Direction\", title3=\"Inverted Direction\", \n",
    "                       title4=\"Warped Grayscale\", title5=\"Warped Direction\", title6=\"Inverted Warped Direction\", \n",
    "                       color=(255,0,0), thickness=5)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(screen)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "# UNCOMMENT TO RUN\n",
    "#demonstrate_direction_gradient_comparison(test_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOAL 5: Detect lane pixels and fit to find the lane boundary.\n",
    "## GOAL 6: Determine the curvature of the lane and vehicle position with respect to center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5-1 Visualize the birdseye warp on test images\n",
    "#     Also: demonstrate taking a histogram of the lower half of the\n",
    "#     image for determining starting points for finding lane lines\n",
    "\n",
    "def demonstrate_birdseye_warp_with_histogram(imgs):\n",
    "    for fname in imgs:\n",
    "\n",
    "        # Read in a test image\n",
    "        img = mpimg.imread(fname)\n",
    "\n",
    "        # Undistort, threshold, warp\n",
    "        binary_warped = get_birdseye_binary_warped(img)\n",
    "        \n",
    "        print (\"binary_warped.shape {}\".format(binary_warped.shape))\n",
    "        \n",
    "        # Count up occurances of 1-values of pixels for lower half of image\n",
    "        histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "\n",
    "        f, (ax1, ax2) = plt.subplots(1,2)\n",
    "        f.tight_layout()\n",
    "\n",
    "        ax1.imshow(binary_warped, cmap='gray')\n",
    "        ax1.set_title(\"Birdseye Threshold\")\n",
    "        \n",
    "        # highlight region that is being considered for histogram\n",
    "        \"\"\"\n",
    "        ax1.add_patch(Polygon([(0, binary_warped.shape[0]), \n",
    "                               (0, binary_warped.shape[0]//2),\n",
    "                               (binary_warped.shape[1]-1, binary_warped.shape[0]//2),\n",
    "                               (binary_warped.shape[1]-1, binary_warped.shape[0])], True, alpha=0.4, color='#eeeeee'))\n",
    "        \"\"\"\n",
    "        ax2.plot(histogram, color='#ff0000')\n",
    "        ax2.set_title(\"Histogram\")\n",
    "\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        plt.show()\n",
    "    \n",
    "# UNCOMMENT TO RUN\n",
    "demonstrate_birdseye_warp_with_histogram([test_images[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5-2 Define functions for calculating the curvature of the lane lines\n",
    "#     in terms of the radius of a circle tangent to an evaluation point.\n",
    "\n",
    "def get_curve_radius(eval_value, fit_coef):\n",
    "    '''\n",
    "    Return the radius of the curve at the specified point.\n",
    "    Using f(y) = Ay^2 + By + C\n",
    "    Where y = eval_value and [A,B,C] are the fit_coef values\n",
    "    Radius = [1 + (dx/dy)^2]^3/2 / |d^2x / dy^2|\n",
    "           = (1 + (2Ay + B)^2)^3/2 / |2A|\n",
    "    http://www.intmath.com/applications-differentiation/8-radius-curvature.php\n",
    "    https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/2b62a1c3-e151-4a0e-b6b6-e424fa46ceab/lessons/40ec78ee-fb7c-4b53-94a8-028c5c60b858/concepts/2f928913-21f6-4611-9055-01744acc344f    \n",
    "    '''\n",
    "    return ((1 + (2*fit_coef[0]*eval_value + fit_coef[1])**2)**1.5) / np.absolute(2*fit_coef[0])\n",
    "\n",
    "def convert_x_pixels_to_meters(values):\n",
    "    return np.multiply(values, 0.00528571) # 3.7/700 meters/pixel in x dimension\n",
    "\n",
    "def convert_y_pixels_to_meters(values):\n",
    "    return np.multiply(values, 0.04166667) # 30/720 meters/pixel in y dimension\n",
    "\n",
    "def convert_pixels_to_meters(x_values, y_values):\n",
    "    ''' Convenience method. Scales x and y coordinates from the birds-eye view to their\n",
    "        equivalent values in meters in real-world space.\n",
    "    ''' \n",
    "    return convert_x_pixels_to_meters(x_values), convert_y_pixels_to_meters(y_values)\n",
    "\n",
    "def get_curve_radius_in_meters(ploty, x_values):\n",
    "    ''' Scales plot points for a birds-eye curve from pixel coordinates to\n",
    "        meters, re-performs a polyfit to get the appropriate polynomial\n",
    "        coefficients, then evaluates the curve radius equation at the\n",
    "        point at the bottom of the image.\n",
    "    '''\n",
    "    \n",
    "    # Convert the pixel values to meter values\n",
    "    conv_x, conv_y = convert_pixels_to_meters(x_values, ploty)\n",
    "    \n",
    "    # Find new fit polynomial values based on the new input\n",
    "    conv_fit = np.polyfit(conv_y, conv_x, 2)\n",
    "    \n",
    "    # Grab the max y-value\n",
    "    y_eval = np.max(conv_y)\n",
    "    \n",
    "    # Return the radius at that point\n",
    "    return get_curve_radius(y_eval, conv_fit)\n",
    "\n",
    "def get_curve_radii_in_pixels(ploty, left_fit, right_fit):\n",
    "    ''' Convenience method for getting the curvature of the left and right\n",
    "        lane lines in pixels.\n",
    "    '''\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # In this case, the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    left_curverad = get_curve_radius(y_eval, left_fit)\n",
    "    right_curverad = get_curve_radius(y_eval, right_fit)\n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "def get_curve_radii_in_meters(ploty, leftx, rightx):\n",
    "    ''' Convenience method for getting the curvature of the left and right\n",
    "        lane lines in meters.\n",
    "    '''\n",
    "    left_curverad = get_curve_radius_in_meters(ploty, leftx)\n",
    "    right_curverad = get_curve_radius_in_meters(ploty, rightx)\n",
    "    \n",
    "    return left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5-3 Define functions for calculating the offset from center\n",
    "\n",
    "def eval_poly_at(at, poly_coefficients):\n",
    "    ''' Creates the polynomial defined by the coefficients, then evaluates it at the specified value(s).\n",
    "        If 'at' is a scalar, returns a scalar. If it is an array, performs it for all values and returns\n",
    "        an array of the same dimensions.\n",
    "    '''\n",
    "    poly = np.poly1d(poly_coefficients)\n",
    "    return poly(at)    \n",
    "\n",
    "def get_lane_center_in_pixels(ploty, left_fit, right_fit):\n",
    "    ''' Find the center pixel value between the right and left lines at the bottom of the image.\n",
    "    '''\n",
    "    # Grab the y point at the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    # Evaluate the x points at that y-point\n",
    "    left_x = eval_poly_at(y_eval, left_fit)\n",
    "    right_x = eval_poly_at(y_eval, right_fit)\n",
    "    \n",
    "    return ((right_x + left_x) // 2)\n",
    "\n",
    "def get_lane_offset_in_meters(img_width, lane_center):\n",
    "    ''' Converts the pixel offset to meters '''\n",
    "    return convert_x_pixels_to_meters(img_width//2 - lane_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5-4 Define functions for finding lane lines using the sliding windows method\n",
    "#     described in the Udacity 'Finding the Lines' lesson\n",
    "\n",
    "def find_lane_lines_using_windows(binary_warped):\n",
    "\n",
    "    # This code was taken from the Udacity 'Finding the Lines' section of the\n",
    "    # Advanced Lane Finding lesson\n",
    "    # https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/2b62a1c3-e151-4a0e-b6b6-e424fa46ceab/lessons/40ec78ee-fb7c-4b53-94a8-028c5c60b858/concepts/c41a4b6b-9e57-44e6-9df9-7e4e74a1a49a\n",
    "    \n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    \n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 120\n",
    "    \n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        \n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height  # bottom of image - (next window count * window height)\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height     # bottom of image - (curr window count * window height)\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Color the non-zero values that are part of the lanes\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    return left_fit, right_fit, out_img\n",
    "\n",
    "def visualize_lanes_using_windows(img):\n",
    "    \n",
    "    # Undistort, threshold, warp\n",
    "    binary_warped = get_birdseye_binary_warped(img)\n",
    "\n",
    "    left_fit, right_fit, out_img = find_lane_lines_using_windows(binary_warped)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = eval_poly_at(ploty, left_fit)\n",
    "    right_fitx = eval_poly_at(ploty, right_fit)\n",
    "    \n",
    "    # Visualize the lines\n",
    "    plt.figure()\n",
    "    plt.imshow(out_img)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1296)\n",
    "    plt.ylim(994, 0)\n",
    "    plt.show()\n",
    "    \n",
    "    left_curverad_px, right_curverad_px = get_curve_radii_in_pixels(ploty, left_fit, right_fit)\n",
    "    print(\"left curve {:.3f} px, right curve {:.3f} px\".format(left_curverad_px, right_curverad_px))\n",
    "\n",
    "    left_curverad_m, right_curverad_m = get_curve_radii_in_meters(ploty, left_fitx, right_fitx)\n",
    "    print(\"left curve {:.3f} m, right curve {:.3f} m\".format(left_curverad_m, right_curverad_m))\n",
    "    \n",
    "    lane_center_px = get_lane_center_in_pixels(ploty, left_fit, right_fit)\n",
    "    lane_offset_m = get_lane_offset_in_meters(binary_warped.shape[1], lane_center_px)\n",
    "    print(\"lane center {:.3f} px, offset from lane center {:.3f} m\".format(lane_center_px, lane_offset_m))\n",
    "    \n",
    "    return left_fit, right_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5-5 Visualize the sliding windows functionality on test images\n",
    "\n",
    "def demonstrate_sliding_windows(data):\n",
    "    for idx in range(len(data)):\n",
    "\n",
    "        # Read in a test image\n",
    "        img = mpimg.imread(data[idx])\n",
    "        \n",
    "        print (\"img.shape\", img.shape)\n",
    "\n",
    "        # Process it\n",
    "        left_fit, right_fit = visualize_lanes_using_windows(img)\n",
    "\n",
    "# UNCOMMENT TO RUN\n",
    "demonstrate_sliding_windows(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5-6 Define functions for finding lane lines using previously found fit lines as\n",
    "#     described in the Udacity 'Finding the Lines' lesson\n",
    "\n",
    "def find_lane_lines_from_fit(binary_warped, left_fit, right_fit):\n",
    "\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "\n",
    "    # Assume you now have a new warped binary image \n",
    "    # from the next frame of video (also called \"binary_warped\")\n",
    "    # It's now much easier to find line pixels!\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "\n",
    "    # Determine the location of the left and right lane indices\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    # Color in left and right line pixels\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    return left_fit, right_fit, out_img\n",
    "\n",
    "def visualize_lines_from_fit(img, l_fit, r_fit):\n",
    "    \n",
    "    # Undistort, threshold, warp\n",
    "    binary_warped = get_birdseye_binary_warped(img)\n",
    "\n",
    "    left_fit, right_fit, out_img = find_lane_lines_from_fit(binary_warped, l_fit, r_fit)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = eval_poly_at(ploty, left_fit)\n",
    "    right_fitx = eval_poly_at(ploty, right_fit)\n",
    "\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    \n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    \n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Create an image to show the selection window\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "\n",
    "    # Draw the selection window onto the output image\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(result)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1296)\n",
    "    plt.ylim(994, 0)\n",
    "    plt.show()\n",
    "    \n",
    "    left_curverad_px, right_curverad_px = get_curve_radii_in_pixels(ploty, left_fit, right_fit)\n",
    "    print(\"left curve {:.3f} px, right curve {:.3f} px\".format(left_curverad_px, right_curverad_px))\n",
    "\n",
    "    left_curverad_m, right_curverad_m = get_curve_radii_in_meters(ploty, left_fitx, right_fitx)\n",
    "    print(\"left curve {:.3f} m, right curve {:.3f} m\".format(left_curverad_m, right_curverad_m))\n",
    "    \n",
    "    lane_center_px = get_lane_center_in_pixels(ploty, left_fit, right_fit)\n",
    "    lane_offset_m = get_lane_offset_in_meters(binary_warped.shape[1], lane_center_px)\n",
    "    print(\"lane center {:.3f} px, offset from lane center {:.3f} m\".format(lane_center_px, lane_offset_m))\n",
    "\n",
    "    return left_fit, right_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5-7 Now run our visualization functions defined above on some of the images\n",
    "\n",
    "def demonstrate_image_processing_on_video_frames():\n",
    "    left_fit = []\n",
    "    right_fit = []\n",
    "\n",
    "    for img in extract_frames('project_video', start_time=0.0, interval=0.1, max_images=3):\n",
    "\n",
    "        '''\n",
    "        # Uncomment this code to further visualize some of the intermediate states\n",
    "        # of the image processing pipeline.\n",
    "        \n",
    "        undistorted = cal_undistort(img)\n",
    "        undistorted_warped = birdseye.warp(undistorted)\n",
    "\n",
    "        binary = combined_thresh(undistorted)\n",
    "        binary_warped = birdseye.warp(binary)\n",
    "\n",
    "\n",
    "        f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 14))\n",
    "        f.tight_layout()\n",
    "\n",
    "        ax1.imshow(undistorted)\n",
    "        ax1.set_title('Undistorted', fontsize=50)\n",
    "        ax1.add_patch(Polygon(birdseye.src, True, edgecolor='#ff0000', fill=False))\n",
    "\n",
    "        ax2.imshow(undistorted_warped)\n",
    "        ax2.set_title('Undistorted -> Warped', fontsize=50)\n",
    "        ax2.add_patch(Polygon(birdseye.dst, True, edgecolor='#ff0000', fill=False))\n",
    "\n",
    "        ax3.imshow(binary, cmap='gray')\n",
    "        ax3.set_title('Undistorted -> Thresholded', fontsize=50)\n",
    "        ax3.add_patch(Polygon(birdseye.src, True, edgecolor='#ff0000', fill=False))\n",
    "\n",
    "        ax4.imshow(binary_warped, cmap='gray')\n",
    "        ax4.set_title('Thresholded -> Warped', fontsize=50)\n",
    "        ax4.add_patch(Polygon(birdseye.dst, True, edgecolor='#ff0000', fill=False))\n",
    "\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        plt.show()\n",
    "        '''\n",
    "\n",
    "        if ((len(left_fit) == 0) or (len(right_fit) == 0)):\n",
    "            left_fit, right_fit = visualize_lanes_using_windows(img)\n",
    "        else:\n",
    "            left_fit, right_fit = visualize_lines_from_fit(img, left_fit, right_fit)\n",
    "            \n",
    "# UNCOMMENT TO RUN\n",
    "#demonstrate_image_processing_on_video_frames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## GOAL 7: Warp the detected lane boundaries back onto the original image.\n",
    "## GOAL 8: Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "Note: the line-finding code above has been re-implemented below using a Line class to maintain state between frames and logic has been put in place to check the sanity of the fit curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7-1 Define our own line plotting function using numpy and opencv\n",
    "#     so that plotting to a matplotlib figure doesn't need to be used.\n",
    "\n",
    "def plot_line(img, x, y, color=(255,255,0), thickness=2):\n",
    "    ''' Takes an image and two arrays of x and y points similar to matplotlib\n",
    "        and writes the lines onto the image. If the points are floats, they\n",
    "        are rounded and converted to ints to satisfy opencv.\n",
    "    '''\n",
    "    points = np.rint(np.vstack([x,y]).T).astype(int)\n",
    "    #print(points)\n",
    "    cv2.polylines(img, [points], False, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7-2 Test our line plotting function\n",
    "\n",
    "def demonstrate_plotting_function():\n",
    "    test_img = np.zeros((128, 128, 3), dtype='uint8')\n",
    "\n",
    "    x = np.array([40.1,60,80,100])\n",
    "    y = np.array([82.6,102,50,20])\n",
    "\n",
    "    plot_line(test_img, x, y)\n",
    "\n",
    "    plt.imshow(test_img)\n",
    "    plt.show()\n",
    "    \n",
    "# UNCOMMENT TO RUN\n",
    "#demonstrate_plotting_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7-3 Define some functions for helping to predict where the lane might be\n",
    "#     based on previous line data in the event that a line can't be determined.\n",
    "\n",
    "# Predicts the next values based on a softmax weighted averages of the\n",
    "# differences between the n-last previous values.\n",
    "\n",
    "def softmax(x):\n",
    "    '''Compute softmax values for each value in x.'''\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def find_weighted_averages(data, window=2):\n",
    "    ''' Given an array of arrays, calculates the averages along the 0 axis for\n",
    "        for the past few elements (default 2) weighted by a softmax function,\n",
    "        with the heaviest weights at the end of the window.\n",
    "        'window' must be an integer between 1 and the length of the enclosing array.\n",
    "        Returns a numpy array.\n",
    "    '''\n",
    "    result = []\n",
    "    weights = softmax(np.array(list(range(window))))\n",
    "\n",
    "    for i in range(len(data)):\n",
    "    \n",
    "        if (i >= window-1):\n",
    "            # Use the full window previously defined if possible\n",
    "            avg = np.average(data[i-(window-1):i+1], axis=0, weights=weights)\n",
    "        else:\n",
    "            # Otherwise, too close to an edge so recalculate weights for smaller window\n",
    "            alt_weights = softmax(np.array(list(range(i+1))))\n",
    "            avg = np.average(data[0:i+1], axis=0, weights=alt_weights)\n",
    "\n",
    "        result.append(avg)\n",
    "\n",
    "    return result\n",
    "\n",
    "def predict_next_values(data, window=2):\n",
    "    ''' Predict the next set of numbers by applying the last weighted avg of the diffs to the last data set '''\n",
    "\n",
    "    # If empty array, just return it\n",
    "    if (len(data) == 0):\n",
    "        return data\n",
    "\n",
    "    # If there's only one element, return that element as the prediction    \n",
    "    if (len(data) == 1):\n",
    "        return data[0]\n",
    "\n",
    "    # Otherwise perform the weighted average of the diffs\n",
    "    diffs = np.diff(data, axis=0)\n",
    "    wavgs = find_weighted_averages(diffs, window=window)\n",
    "    return np.add(wavgs[-1], data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7-4 Test performing a softmax weighted average over a series of points \n",
    "#     and predicting next set of points.\n",
    "\n",
    "def demonstrate_weighted_average_and_prediction():\n",
    "\n",
    "    # Create a blank array to be used as an image\n",
    "    test_img = np.zeros((128, 128, 3), dtype='uint8')\n",
    "\n",
    "    # Define common y-points\n",
    "    y = np.array([0,31,63,95,127])\n",
    "\n",
    "    # Define an array of x-point arrays\n",
    "    #recent_x = np.array([[40,40,40,40,40]])\n",
    "    #recent_x = np.array([[40,40,40,40,40], [30,35,37,39,40]])\n",
    "    #recent_x = np.array([[40,40,40,40,40], [30,35,37,39,40], [20,30,35,38,40], [10,25,32,37,40]])\n",
    "    #recent_x = np.array([[40,40,40,40,40], [30,35,37,39,40], [20,30,35,38,40], [10,25,32,37,40], [20,30,35,38,40]])\n",
    "    recent_x = np.array([[40,40,40,40,40], [30,35,37,39,40], [20,30,35,38,40], [10,25,32,37,40], [0,20,29,36,40]])\n",
    "    print (\"recent_x\", recent_x)\n",
    "\n",
    "    # Calculate the softmax weighted averages for the x-points\n",
    "    averages = find_weighted_averages(recent_x, window=3)\n",
    "    print(\"weighted averages\", averages)\n",
    "\n",
    "    # Calculate the differences between the each consecutive set of x-points\n",
    "    recent_xdiff = np.diff(recent_x, axis=0)\n",
    "    print (\"recent_xdiff\", recent_xdiff)\n",
    "\n",
    "    if len(recent_xdiff) != 0:\n",
    "        # Calculate the non-weighted average of the differences for a baseline\n",
    "        recent_xdiff_avg = np.average(recent_xdiff, axis=0)\n",
    "        print (\"recent_xdiff_avg\", recent_xdiff_avg)\n",
    "\n",
    "        # Calculate the softmax weighted averages for the differences in the x-points\n",
    "        xdiff_weighted_averages = find_weighted_averages(recent_xdiff, window=2)\n",
    "        print(\"xdiff_weighted_averages[-1]:\", xdiff_weighted_averages[-1])\n",
    "\n",
    "    # Predict the next line location by applying the last weighted diff to the last x-points \n",
    "    #predicted_x = np.add(xdiff_weighted_averages[-1], recent_x[-1])\n",
    "    predicted_x = predict_next_values(recent_x, window=2)\n",
    "    print(\"predicted:\", predicted_x)\n",
    "\n",
    "    # Plot the various lines\n",
    "    for i in range(len(recent_x)):\n",
    "        # Plot a red line for the weighted moving averages\n",
    "        plot_line(test_img, averages[i], y, thickness=1, color=(200,0,0))\n",
    "\n",
    "        # Plot a yellow line for the current points\n",
    "        plot_line(test_img, recent_x[i], y, thickness=1)\n",
    "\n",
    "    # Plot a green line for the predicted next line based on weighted averages of the diffs\n",
    "    plot_line(test_img, predicted_x, y, thickness=1, color=(0,200,0))\n",
    "\n",
    "    plt.imshow(test_img)\n",
    "    plt.show()\n",
    "\n",
    "# UNCOMMENT TO RUN\n",
    "#demonstrate_weighted_average_and_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7-5 Define a class to receive the characteristics of each line detection\n",
    "\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False\n",
    "        \n",
    "        # x-values for detected line pixels\n",
    "        self.detected_pixelsx = None\n",
    "        \n",
    "        # y-values for detected line pixels\n",
    "        self.detected_pixelsy = None\n",
    "\n",
    "        # polynomial coefficients for the fit to the detected pixels\n",
    "        self.detected_fit = [np.array([False])]\n",
    "        \n",
    "        # x-values resulting from evaluating detected_fit at the y-values\n",
    "        self.detected_fitx = None\n",
    "\n",
    "        # polynomial coefficients for the fit that was actually used\n",
    "        # This may be the same as detected_fit, or a predicted value based on\n",
    "        # the differences in the recent history\n",
    "        self.used_fit = [np.array([False])]\n",
    "        \n",
    "        # x-values resulting from evaluating used_fit at the y-values\n",
    "        self.used_fitx = None        \n",
    "        \n",
    "        # Depth of the history to keep\n",
    "        self.history_depth = 5\n",
    "\n",
    "        # x-values of the last history_depth fits of the line\n",
    "        self.recent_fitxs = []\n",
    "        \n",
    "        # Polynomial coefficients for the polynomial fit to the best_fitx\n",
    "        self.best_fit = [np.array([False])]\n",
    "\n",
    "        # Weighted average of x-values from recent_fitxs values\n",
    "        self.best_fitx = None\n",
    "        \n",
    "        # Image showing detected line pixels decayed over last history_depth iterations\n",
    "        #self.history_heatmap = None\n",
    "        \n",
    "        #radius of curvature of the best_fit line in pixels\n",
    "        self.radius_of_curvature_px = None\n",
    "        \n",
    "        #radius of curvature of the best_fit line in meters\n",
    "        self.radius_of_curvature_m = None\n",
    "    \n",
    "    def predict_next_fitx(self):\n",
    "        #return self.recent_fitxs[-1]\n",
    "        return predict_next_values(self.recent_fitxs, window=self.history_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 7-6 Demonstrate a gaussian plot\n",
    "\n",
    "def show_gauss_plot(width=111):\n",
    "    mu, sigma = 0, 0.2\n",
    "    bins = np.linspace(-0.6, 0.6, width)\n",
    "    gauss = 1/(sigma * np.sqrt(2 * np.pi)) * np.exp( - (bins - mu)**2 / (2 * sigma**2))\n",
    "    norm_gauss = gauss / np.max(gauss)\n",
    "    \n",
    "    plt.plot(norm_gauss, linewidth=2, color='r')\n",
    "    plt.show()\n",
    "    \n",
    "# UNCOMMENT TO RUN\n",
    "#show_gauss_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7-7 Calculate a gaussian distribution of the specified width using\n",
    "#     the pre-defined mu and sigma values below.\n",
    "\n",
    "def get_gaussian_filter(width=51):\n",
    "    mu, sigma = 0, 0.2\n",
    "    bins = np.linspace(-0.6, 0.6, width)\n",
    "    gauss = 1/(sigma * np.sqrt(2 * np.pi)) * np.exp( - (bins - mu)**2 / (2 * sigma**2))\n",
    "    return gauss / np.max(gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7-8 Apply a gaussian filter horizontally along a series of x-values to\n",
    "#     smoothly diminish the effect of pixels to the left and right of the\n",
    "#     curve.\n",
    "\n",
    "def apply_horizontal_gaussian(data, xfit, margin=120, min_thresh=255):\n",
    "    ''' Applies a horizontal gaussian filter for the xfit values\n",
    "        in the data.\n",
    "    '''\n",
    "    # ensure we are dealing with ints since they are used as indexes\n",
    "    rounded_xfit = np.rint(xfit).astype(int)\n",
    "    \n",
    "    # generate the common filter once\n",
    "    gauss_filter = get_gaussian_filter(margin*2)\n",
    "    \n",
    "    # for all rows in the image\n",
    "    for j in range(data.shape[0]):\n",
    "        \n",
    "        # determine the range of the window (don't go past borders)\n",
    "        mini = max(0, rounded_xfit[j] - margin)\n",
    "        maxi = min(rounded_xfit[j] + margin, data.shape[1])\n",
    "\n",
    "        # check the length of the subset we want to modify\n",
    "        sublen = len(data[j][mini:maxi])\n",
    "        \n",
    "        # apply the filter to the subset and put it back into the data\n",
    "        if (sublen != margin*2):\n",
    "            # if the size of the subset is less than the intended window, use a custom size filter\n",
    "            data[j][mini:maxi] = np.multiply(data[j][mini:maxi], get_gaussian_filter(sublen))\n",
    "        else:\n",
    "            data[j][mini:maxi] = np.multiply(data[j][mini:maxi], gauss_filter)\n",
    "        #print(\"mini:\", mini, \"maxi:\", maxi, \"len data[j][mini:maxi]\", len(data[j][mini:maxi]), \"sublen:\", sublen, \"margin*2\", margin*2, \"len gfilt\", len(gauss_filter))\n",
    "    \n",
    "    # if we want to apply a threshold, select only data greater\n",
    "    # than that (removes negligible values)\n",
    "    if (min_thresh < 255):\n",
    "        mask = data > min_thresh\n",
    "        data = np.multiply(data, mask)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7-9 Define methods for comparing lines\n",
    "\n",
    "def determine_line_polynomial_similarity(line1_fit, line2_fit):\n",
    "    print (\"line1 fit:\", line1_fit)\n",
    "    print (\"line2 fit:\", line2_fit)\n",
    "    diff = line1_fit - line2_fit\n",
    "    print (\"line fit diff:\", diff)\n",
    "    \n",
    "def measure_relative_line_curvature(line_fitx):\n",
    "    len_fitx = len(line_fitx)\n",
    "    avg_top_fitx = np.mean(line_fitx[:len_fitx//3]).astype(int)\n",
    "    avg_mid_fitx = np.mean(line_fitx[len_fitx//3:(2*len_fitx)//3]).astype(int)\n",
    "    avg_bot_fitx = np.mean(line_fitx[(2*len_fitx)//3:]).astype(int)\n",
    "    \n",
    "    top_diff = avg_top_fitx - avg_mid_fitx\n",
    "    bot_diff = avg_mid_fitx - avg_bot_fitx\n",
    "    \n",
    "    return top_diff, bot_diff\n",
    "\n",
    "def lines_are_similar(y, line1_fit, line2_fit):\n",
    "    ''' TODO: Implement this if necessary '''\n",
    "    #line_diff = np.subtract(right_fitx, left_fitx).astype(int)\n",
    "    #line_mean = np.mean(line_diff).astype(int)\n",
    "    #print(\"TODO: Implement lines_are_similar (l1:{} l2:{})\".format(line1_fit, line2_fit))\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7-10 Define the line finding algorithms using the Line class, do some predictive \n",
    "#      assumptions, check sanity of findings, fallback if necessary\n",
    "\n",
    "def find_line_indices_using_sliding_windows(binary_warped, nonzerox, nonzeroy, margin=110):\n",
    "    \n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    \n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "        \n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    left_lane_windows = []\n",
    "    right_lane_windows = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        \n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height  # bottom of image - (next window count * window height)\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height     # bottom of image - (curr window count * window height)\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Save the window rect coordinates for drawing later\n",
    "        left_lane_windows.append([(win_xleft_low,win_y_low),(win_xleft_high,win_y_high)])\n",
    "        right_lane_windows.append([(win_xright_low,win_y_low),(win_xright_high,win_y_high)])\n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    return left_lane_inds, right_lane_inds, left_lane_windows, right_lane_windows\n",
    "\n",
    "'''\n",
    "def fit_from_history_heatmap(x, y, ploty, prev_line=None, img=None):\n",
    "    \n",
    "    # Grab any historical information we have\n",
    "    if (prev_line is not None):\n",
    "        # Decay the previous history heatmap\n",
    "        history_heatmap = np.rint(prev_line.history_heatmap * 0.8).astype(np.uint8)\n",
    "        # Grab our next best guess for where the line will be\n",
    "        next_fitx = prev_line.predict_next_fitx()\n",
    "    else:\n",
    "        # If no history heatmap, initialize some\n",
    "        history_heatmap = np.array(np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8))\n",
    "        # Generate a fit based on the pixel data we have detected\n",
    "        next_fit = np.polyfit(y, x, 2)\n",
    "        # Grab the x-values that fit the line we plan to use\n",
    "        next_fitx = eval_poly_at(ploty, next_fit)\n",
    "        \n",
    "    # Add the new pixel information to the history heatmap\n",
    "    history_heatmap[y, x] = 255\n",
    "    \n",
    "    # Apply a horizontal gausian to focus on where we expect the line to be\n",
    "    history_heatmap = apply_horizontal_gaussian(history_heatmap, next_fitx, margin=300, min_thresh=143)\n",
    "    \n",
    "    # Grab the non-zero coordinates that passed the threshold\n",
    "    hist_nonzero = history_heatmap.nonzero()\n",
    "    hist_nz_y = np.array(hist_nonzero[0])\n",
    "    hist_nz_x = np.array(hist_nonzero[1]) \n",
    "    \n",
    "    # Fit a second order polynomial to\n",
    "    return np.polyfit(hist_nz_y, hist_nz_x, 2), history_heatmap\n",
    "'''\n",
    "\n",
    "def find_lane_lines(binary_warped, margin=100, method='sliding_windows', \n",
    "                    prev_left_line=None, prev_right_line=None, produce_out_img=True):\n",
    "\n",
    "    # This code was adapted from the Udacity 'Finding the Lines' section of the\n",
    "    # Advanced Lane Finding lesson\n",
    "    # https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/2b62a1c3-e151-4a0e-b6b6-e424fa46ceab/lessons/40ec78ee-fb7c-4b53-94a8-028c5c60b858/concepts/c41a4b6b-9e57-44e6-9df9-7e4e74a1a49a\n",
    "    \n",
    "    ####\n",
    "    # 1. Try to identify the lane lines in the image\n",
    "    \n",
    "    # Identify the x and y positions of all non-zero valued pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Try to select only the points related to the the lines\n",
    "    \n",
    "    # If we have a previous line, use the 'previous fit' method to get the indexes\n",
    "    # of the nonzero values associated with the lines\n",
    "    if ((method == 'previous_fit') and \n",
    "        (prev_left_line is not None) and (prev_left_line.detected != False) and\n",
    "        (prev_right_line is not None) and (prev_right_line.detected != False)):\n",
    "        \n",
    "        # Grab the fitx points along the line for all of the non-zero pixel y-values\n",
    "        left_nonzerofitx = eval_poly_at(nonzeroy, prev_left_line.best_fit)\n",
    "        right_nonzerofitx = eval_poly_at(nonzeroy, prev_right_line.best_fit)\n",
    "        \n",
    "        # Grab the indices of any non-zero pixels that are within the specified margin of the fitx points\n",
    "        left_lane_inds = ((nonzerox > (left_nonzerofitx - margin)) & (nonzerox < (left_nonzerofitx + margin))) \n",
    "        right_lane_inds = ((nonzerox > (right_nonzerofitx - margin)) & (nonzerox < (right_nonzerofitx + margin)))\n",
    "        \n",
    "        # Initialize empty arrays for the windows, which are not used for this method but will\n",
    "        # be consulted later for drawing to the output image.\n",
    "        left_lane_windows, right_lane_windows = [], []\n",
    "    else:\n",
    "        # Otherwise fall back to the sliding windows method\n",
    "        left_lane_inds, right_lane_inds, left_lane_windows, right_lane_windows = find_line_indices_using_sliding_windows(binary_warped, nonzerox, nonzeroy, margin=margin)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Generate y values for plotting and fitting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    \n",
    "    # Fit a second order polynomial using any historical information if possible\n",
    "    # Otherwise, just use the non-zero pixels we detected\n",
    "    #left_fit, left_history_heatmap = fit_from_history_heatmap(leftx, lefty, ploty, prev_line=prev_left_line, img=binary_warped)\n",
    "    #right_fit, right_history_heatmap = fit_from_history_heatmap(rightx, righty, ploty, prev_line=prev_right_line, img=binary_warped)\n",
    "\n",
    "    # Fit a second order polynomial to each group of pixels\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    if (produce_out_img):\n",
    "        # Create an output image to draw on and visualize the result and\n",
    "        # Color the non-zero values that are part of the lanes\n",
    "        #out_img = np.dstack((left_history_heatmap, np.zeros_like(left_history_heatmap), right_history_heatmap))\n",
    "\n",
    "        # Create an output image to draw on and visualize the result and\n",
    "        # Color the non-zero values that are part of the lanes\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "        out_img[lefty, leftx] = [255, 0, 0]\n",
    "        out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "        # Draw the windows on the visualization image (if there are any to draw)\n",
    "        for rect_points in left_lane_windows:\n",
    "            cv2.rectangle(out_img, rect_points[0], rect_points[1], (0,255,0), 2)\n",
    "        for rect_points in right_lane_windows:\n",
    "            cv2.rectangle(out_img, rect_points[0], rect_points[1], (0,255,0), 2)\n",
    "\n",
    "    ####\n",
    "    # 2. Now check the sanity of the curves we tried to detect\n",
    "\n",
    "    sane_left = True\n",
    "    sane_right = True\n",
    "\n",
    "    # Generate x-values for plotting and conversion to meters\n",
    "    left_fitx = eval_poly_at(ploty, left_fit)\n",
    "    right_fitx = eval_poly_at(ploty, right_fit)\n",
    "\n",
    "    # Calculate the curvature radius in pixels at the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    left_radius_of_curvature_px = get_curve_radius(y_eval, left_fit)\n",
    "    right_radius_of_curvature_px = get_curve_radius(y_eval, right_fit)\n",
    "\n",
    "    # Calculate the curvature radius in meters\n",
    "    # The image size and fitx values need to be specified since the x- and y-\n",
    "    # values need to be scaled before fitting a line and evaluating at a point.\n",
    "    left_radius_of_curvature_m = get_curve_radius_in_meters(ploty, left_fitx)\n",
    "    right_radius_of_curvature_m = get_curve_radius_in_meters(ploty, right_fitx)\n",
    "\n",
    "    # - Check that Left and Right curvature is not too small (<100)\n",
    "    if (left_radius_of_curvature_m < 100):\n",
    "        print(\"WARNING: left_radius_of_curvature_m < 100:\", left_radius_of_curvature_m)\n",
    "        sane_left = False        \n",
    "\n",
    "    if (right_radius_of_curvature_m < 100):\n",
    "        print(\"WARNING: right_radius_of_curvature_m < 100:\", right_radius_of_curvature_m)\n",
    "        sane_right = False\n",
    "\n",
    "    # - Check that Left and Right have similar curvature\n",
    "    left_shape = measure_relative_line_curvature(left_fitx)\n",
    "    #print(\"left_shape\", left_shape)\n",
    "    right_shape = measure_relative_line_curvature(right_fitx)\n",
    "    #print(\"right_shape\", right_shape)\n",
    "        \n",
    "    # - Check that Left and Right are separated by approximately the right distance horizontally\n",
    "    line_diff = np.subtract(right_fitx, left_fitx).astype(int)\n",
    "    line_mean = np.mean(line_diff).astype(int)\n",
    "\n",
    "    if (line_mean > 825) or (line_mean < 525):\n",
    "        print(\"WARNING: mean line_diff out of range: 525 > {} > 825\".format(line_mean))\n",
    "        sane_left = False\n",
    "        sane_right = False\n",
    "    \n",
    "    # - Check that Left and Right are roughly parallel \n",
    "    norm_line_diff = line_diff - line_mean\n",
    "    #print(\"norm_line_diff\", norm_line_diff)\n",
    "    max_line_x_diff = np.max(np.abs(norm_line_diff))\n",
    "    max_line_x_thresh = 140\n",
    "\n",
    "    if (max_line_x_diff > max_line_x_thresh):\n",
    "        print(\"WARNING: max line x diff {} > thresh {}\".format(max_line_x_diff, max_line_x_thresh))\n",
    "        sane_left = False\n",
    "        sane_right = False\n",
    "\n",
    "    ####\n",
    "    # 3. Depending on the sanity check results and past history, figure out what values to use going forward\n",
    "    \n",
    "    left_line = Line()\n",
    "    left_line.detected_fit = left_fit\n",
    "    left_line.detected_pixelsx = leftx\n",
    "    left_line.detected_pixelsy = lefty\n",
    "        \n",
    "    right_line = Line()\n",
    "    right_line.detected_fit = right_fit\n",
    "    right_line.detected_pixelsx = rightx\n",
    "    right_line.detected_pixelsy = righty\n",
    "\n",
    "    if (sane_left):\n",
    "        left_line.detected = True\n",
    "    else:\n",
    "        if (prev_left_line is not None):\n",
    "            left_line.detected = lines_are_similar(ploty, prev_left_line.best_fit, left_fit)\n",
    "        \n",
    "    if (sane_right):\n",
    "        right_line.detected = True    \n",
    "    else:\n",
    "        if (prev_right_line is not None):\n",
    "            right_line.detected = lines_are_similar(ploty, prev_right_line.best_fit, right_fit)\n",
    "    \n",
    "    if ((left_line.detected is False) and (prev_left_line is not None)):\n",
    "        # Predict based on history available in recent_fitxs\n",
    "        left_line.used_fitx = prev_left_line.predict_next_fitx()\n",
    "        left_line.used_fit = np.polyfit(ploty, left_line.used_fitx, 2)        \n",
    "    else:\n",
    "        # Either the line was detected successfully, so use it, or\n",
    "        # we don't have any history to use, so we have no choice but use the fit we have. \n",
    "        # The sliding windows method will be used next time anyway.       \n",
    "        left_line.used_fit = left_fit\n",
    "        left_line.used_fitx = left_fitx\n",
    "\n",
    "    if ((right_line.detected is False) and (prev_right_line is not None)):\n",
    "        # Predict based on history available in recent_fitxs\n",
    "        right_line.used_fitx = prev_right_line.predict_next_fitx()\n",
    "        right_line.used_fit = np.polyfit(ploty, right_line.used_fitx, 2)        \n",
    "    else:\n",
    "        # Either the line was detected successfully, so use it, or\n",
    "        # we don't have any history to use, so we have no choice but use the fit we have. \n",
    "        # The sliding windows method will be used next time anyway.       \n",
    "        right_line.used_fit = right_fit\n",
    "        right_line.used_fitx = right_fitx       \n",
    "    \n",
    "    ###\n",
    "    # 4. Update our recent history and best evaluations\n",
    "    \n",
    "    # Copy previous recent_fitxs values if available\n",
    "    if (prev_left_line is not None):\n",
    "        if (len(prev_left_line.recent_fitxs) == prev_left_line.history_depth):\n",
    "            left_line.recent_fitxs = prev_left_line.recent_fitxs[1:]\n",
    "        else:\n",
    "            left_line.recent_fitxs = prev_left_line.recent_fitxs[:]\n",
    "    # Append the new used_fitx value to the history\n",
    "    left_line.recent_fitxs.append(left_line.used_fitx)\n",
    "\n",
    "    # Copy previous recent_fitxs values if available\n",
    "    if (prev_right_line is not None):\n",
    "        if (len(prev_right_line.recent_fitxs) == prev_right_line.history_depth):\n",
    "            right_line.recent_fitxs = prev_right_line.recent_fitxs[1:]\n",
    "        else:\n",
    "            right_line.recent_fitxs = prev_right_line.recent_fitxs[:]    \n",
    "    # Append the new used_fitx value to the history\n",
    "    right_line.recent_fitxs.append(right_line.used_fitx)\n",
    "\n",
    "    # Update the best_fit and best_fitx values\n",
    "    left_line.best_fitx = find_weighted_averages(left_line.recent_fitxs, left_line.history_depth)[-1]\n",
    "    left_line.best_fit = np.polyfit(ploty, left_line.best_fitx, 2)\n",
    "    \n",
    "    right_line.best_fitx = find_weighted_averages(right_line.recent_fitxs, right_line.history_depth)[-1]\n",
    "    right_line.best_fit = np.polyfit(ploty, right_line.best_fitx, 2)    \n",
    "\n",
    "    ####\n",
    "    # 5. Calculate the radius based on the best values\n",
    " \n",
    "    left_line.radius_of_curvature_px = get_curve_radius(y_eval, left_line.best_fit)\n",
    "    left_line.radius_of_curvature_m = get_curve_radius_in_meters(ploty, left_line.best_fitx)\n",
    "\n",
    "    right_line.radius_of_curvature_px = get_curve_radius(y_eval, right_line.best_fit)\n",
    "    right_line.radius_of_curvature_m = get_curve_radius_in_meters(ploty, right_line.best_fitx)\n",
    "\n",
    "    if (produce_out_img):\n",
    "        # Draw the search window on the output image if using the previous fit method\n",
    "        if (method == 'previous_fit'):\n",
    "\n",
    "            # Generate a polygon to illustrate the search window area\n",
    "            # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "            left_line_window1 = np.array([np.transpose(np.vstack([left_fitx - margin, ploty]))])\n",
    "            left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx + margin, ploty])))])\n",
    "            left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "\n",
    "            right_line_window1 = np.array([np.transpose(np.vstack([right_fitx - margin, ploty]))])\n",
    "            right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx + margin, ploty])))])\n",
    "            right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "            # Create an image to show the selection window\n",
    "            window_img = np.zeros_like(out_img)\n",
    "            cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "            cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "\n",
    "            # Draw the selection window onto the output image\n",
    "            out_img = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "\n",
    "        # Draw the used lines on the output image\n",
    "        if (left_line.detected):\n",
    "            plot_line(out_img, left_line.used_fitx, ploty)\n",
    "        else:\n",
    "            plot_line(out_img, left_line.used_fitx, ploty, color=(0,255,255))\n",
    "\n",
    "        if (right_line.detected):\n",
    "            plot_line(out_img, right_line.used_fitx, ploty)\n",
    "        else:\n",
    "            plot_line(out_img, right_line.used_fitx, ploty, color=(0,255,255))\n",
    "\n",
    "        # Draw the best lines on the output image\n",
    "        plot_line(out_img, left_line.best_fitx, ploty, color=(255,0,255))\n",
    "        plot_line(out_img, right_line.best_fitx, ploty, color=(255,0,255))\n",
    "    else:\n",
    "        out_img = None\n",
    "    \n",
    "    return left_line, right_line, out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7-11 Define some visualization methods\n",
    "\n",
    "def draw_lane_on_image(img, binary_warped, ploty, left_fitx, right_fitx):\n",
    "    \n",
    "    global birdseye\n",
    "    \n",
    "    # Create an image to draw the projected lines on\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "    # Warp the blank back to original image space\n",
    "    new_warp = birdseye.unwarp(color_warp)\n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    return cv2.addWeighted(img, 1, new_warp, 0.3, 0)\n",
    "\n",
    "def visualize_lanes_using_matplotlib(img, left_line=None, right_line=None):\n",
    "    \n",
    "    global objpoints, imgpoints\n",
    "    \n",
    "    # Undistort, threshold, warp\n",
    "    img = cal_undistort(img)\n",
    "    binary_warped = get_birdseye_binary_warped(img, undistort=False)\n",
    "    \n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 80\n",
    "\n",
    "    if ((left_line == None) or (right_line == None)):\n",
    "        left_line, right_line, out_img = find_lane_lines(binary_warped, margin=margin, method='sliding_windows')\n",
    "    else:\n",
    "        left_line, right_line, out_img = find_lane_lines(binary_warped, margin=margin, method='previous_fit', \n",
    "                                                         prev_left_line=left_line, prev_right_line=right_line)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "\n",
    "    result = draw_lane_on_image(img, binary_warped, ploty, left_line.best_fitx, right_line.best_fitx)\n",
    "\n",
    "    # Visualize the lines\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(out_img)\n",
    "    ax1.set_title('Birds Eye', fontsize=50)\n",
    "    ax1.set_xlim(0, 1280)\n",
    "    ax1.set_ylim(720, 0) \n",
    "    ax2.imshow(result)\n",
    "    ax2.set_title('Lane detected', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"left curve {:.3f} px, right curve {:.3f} px\".format(left_line.radius_of_curvature_px, right_line.radius_of_curvature_px))\n",
    "    print(\"left curve {:.3f} m, right curve {:.3f} m\".format(left_line.radius_of_curvature_m, right_line.radius_of_curvature_m))\n",
    "\n",
    "    lane_center_px = get_lane_center_in_pixels(ploty, left_line.best_fit, right_line.best_fit)\n",
    "    lane_offset_m = get_lane_offset_in_meters(binary_warped.shape[1], lane_center_px)\n",
    "    print(\"lane center {:.3f} px, offset from lane center {:.3f} m\".format(lane_center_px, lane_offset_m))\n",
    "    \n",
    "    return left_line, right_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7-12 Test the new functions on test images\n",
    "\n",
    "def demonstrate_lane_finding_on_test_images():\n",
    "    for idx in range(len(test_images)):\n",
    "\n",
    "        # Read in a test image\n",
    "        img = mpimg.imread(test_images[idx])\n",
    "\n",
    "        # Process it\n",
    "        left_line, right_line = visualize_lanes_using_matplotlib(img)\n",
    "\n",
    "# UNCOMMENT TO RUN\n",
    "#demonstrate_lane_finding_on_test_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7-13 Test the new functions on frames from the project video\n",
    "\n",
    "def demonstrate_lane_finding_on_video_frames():\n",
    "    \n",
    "    left_line = None\n",
    "    right_line = None\n",
    "\n",
    "    i_frame = 0\n",
    "    for img in extract_frames('project_video', start_time=22.2, interval=1/24, max_images=15):\n",
    "\n",
    "        print(\"frame:\", i_frame)\n",
    "\n",
    "        left_line, right_line = visualize_lanes_using_matplotlib(img, left_line, right_line)\n",
    "\n",
    "        i_frame += 1\n",
    "        \n",
    "# UNCOMMENT TO RUN\n",
    "#demonstrate_lane_finding_on_video_frames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to process the video and diagnose the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7-14 Define some additional diagnostic functions\n",
    "#      Adapted from https://carnd-forums.udacity.com/questions/32706990/answers/38548228\n",
    "\n",
    "def compose_diagScreen(curverad=0, offset=0, \n",
    "                       mainDiagScreen=None, diag1=None, diag2=None, diag3=None, diag4=None, \n",
    "                       diag5=None, diag6=None, diag7=None, diag8=None, diag9=None):\n",
    "\n",
    "    # Initialize the output image. Dimensions: 1080 H x 1920 W\n",
    "    diagScreen = np.zeros((1080, 1920, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Main screen (720x1280) in upper left\n",
    "    if mainDiagScreen is not None:\n",
    "        diagScreen[0:720, 0:1280] = mainDiagScreen\n",
    "    \n",
    "    # Four small (240x320) diagnostic screens in upper right\n",
    "    if diag1 is not None:\n",
    "        diagScreen[0:240, 1280:1600] = cv2.resize(to_RGB(diag1), (320,240), interpolation=cv2.INTER_AREA) \n",
    "    if diag2 is not None:\n",
    "        diagScreen[0:240, 1600:1920] = cv2.resize(to_RGB(diag2), (320,240), interpolation=cv2.INTER_AREA)\n",
    "    if diag3 is not None:\n",
    "        diagScreen[240:480, 1280:1600] = cv2.resize(to_RGB(diag3), (320,240), interpolation=cv2.INTER_AREA)\n",
    "    if diag4 is not None:\n",
    "        diagScreen[240:480, 1600:1920] = cv2.resize(to_RGB(diag4), (320,240), interpolation=cv2.INTER_AREA)*4\n",
    "    \n",
    "    # Gap of 120x320 on right side\n",
    "    \n",
    "    # One medium (480x640) diagnostic screen in lower right\n",
    "    if diag7 is not None:\n",
    "        diagScreen[600:1080, 1280:1920] = cv2.resize(to_RGB(diag7), (640,480), interpolation=cv2.INTER_AREA)*4\n",
    "    \n",
    "    # Middle panel (120x1280) below main screen on left side\n",
    "\n",
    "    # Use cv2 for drawing text in diagnostic pipeline.\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "    middlepanel = np.zeros((120, 1280, 3), dtype=np.uint8)\n",
    "    cv2.putText(middlepanel, 'Estimated lane curvature: {:5.3f} m'.format(curverad), (30, 60), font, 1, (255,0,0), 2)\n",
    "    cv2.putText(middlepanel, 'Estimated offset from center of lane: {:.3f} m'.format(offset), (30, 90), font, 1, (255,0,0), 2)\n",
    "\n",
    "    diagScreen[720:840, 0:1280] = middlepanel\n",
    "    \n",
    "    # Four small (240x320) diagnostic screens in lower left \n",
    "    if diag5 is not None:\n",
    "        diagScreen[840:1080, 0:320] = cv2.resize(to_RGB(diag5), (320,240), interpolation=cv2.INTER_AREA)\n",
    "    if diag6 is not None:\n",
    "        diagScreen[840:1080, 320:640] = cv2.resize(to_RGB(diag6), (320,240), interpolation=cv2.INTER_AREA)\n",
    "    if diag8 is not None:\n",
    "        diagScreen[840:1080, 640:960] = cv2.resize(to_RGB(diag8), (320,240), interpolation=cv2.INTER_AREA)\n",
    "    if diag9 is not None:\n",
    "        diagScreen[840:1080, 960:1280] = cv2.resize(to_RGB(diag9), (320,240), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    return diagScreen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7-15 Visualize the various states of the image processing pipeline to diagnose\n",
    "#      issues.\n",
    "\n",
    "def visualize_lanes_using_diagnostic_screen(img, left_line=None, right_line=None):\n",
    "    \n",
    "    global birdseye, objpoints, imgpoints\n",
    "    \n",
    "    # Undistort, threshold, warp\n",
    "    undistorted = cal_undistort(img)\n",
    "    \n",
    "    # Warp to birds-eye view\n",
    "    warped = birdseye.warp(undistorted)\n",
    "\n",
    "    # Convert to color spaces\n",
    "    gry = cv2.cvtColor(warped, cv2.COLOR_RGB2GRAY)\n",
    "    hls = cv2.cvtColor(warped, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    grad_ksize=27\n",
    "    mag_ksize=27\n",
    "    dir_ksize=15\n",
    "    gradx_thresh=(30, 120)\n",
    "    grady_thresh=(30, 120)\n",
    "    mag_thresh=(30, 120)\n",
    "    dir_thresh=(0.7, 1.57)\n",
    "    lumsat_thresh=(145, 255)\n",
    "            \n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(gry, orient='x', sobel_kernel=grad_ksize, thresh=gradx_thresh)\n",
    "    grady = abs_sobel_thresh(gry, orient='y', sobel_kernel=grad_ksize, thresh=grady_thresh)\n",
    "    mag_binary = grad_magnitude_thresh(gry, sobel_kernel=mag_ksize, thresh=mag_thresh)\n",
    "    dir_binary = grad_direction_thresh(gry, sobel_kernel=dir_ksize, thresh=dir_thresh)\n",
    "\n",
    "    lumsat = (np.float32(hls[:,:,1]) + np.float32(hls[:,:,2]))//2\n",
    "    lumsat_binary = np.zeros_like(gradx)\n",
    "    lumsat_binary[(lumsat >= lumsat_thresh[0]) & (lumsat <= lumsat_thresh[1])] = 1\n",
    "    \n",
    "    # Create combined images for some of these\n",
    "    blank = np.zeros_like(gry).astype(np.uint8)\n",
    "    grad = np.dstack((gradx, grady, blank))*255\n",
    "    magdir = np.dstack((mag_binary, dir_binary, blank))*255\n",
    "    \n",
    "    binary_warped = np.zeros_like(dir_binary).astype(np.uint8)\n",
    "    binary_warped[(((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 0)) | (lumsat_binary == 1))] = 1\n",
    "        \n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 80\n",
    "\n",
    "    if ((left_line == None) or (right_line == None)):\n",
    "        left_line, right_line, out_img = find_lane_lines(binary_warped, margin=margin, method='sliding_windows')\n",
    "    else:\n",
    "        left_line, right_line, out_img = find_lane_lines(binary_warped, margin=margin, method='previous_fit', \n",
    "                                                         prev_left_line=left_line, prev_right_line=right_line)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    \n",
    "    undistorted_overlayed = draw_lane_on_image(undistorted, binary_warped, ploty, left_line.best_fitx, right_line.best_fitx)\n",
    "    \n",
    "    curverad = (left_line.radius_of_curvature_m + right_line.radius_of_curvature_m) / 2\n",
    "    \n",
    "    lane_center_px = get_lane_center_in_pixels(ploty, left_line.best_fit, right_line.best_fit)\n",
    "    lane_offset_m = get_lane_offset_in_meters(binary_warped.shape[1], lane_center_px)\n",
    "\n",
    "    screen = compose_diagScreen(curverad=curverad, offset=lane_offset_m, \n",
    "                                mainDiagScreen=undistorted_overlayed, \n",
    "                                diag1=grad, diag2=magdir, diag3=lumsat_binary, diag4=binary_warped, \n",
    "                                diag5=None, diag6=None, diag7=out_img, diag8=None, diag9=None)\n",
    "\n",
    "    return screen, left_line, right_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 7-16 Test the pipeline on frames from the project video\n",
    "\n",
    "def demonstrate_lane_finding_on_video_frames_with_diag_screen():\n",
    "    left_line = None\n",
    "    right_line = None\n",
    "\n",
    "    for img in extract_frames('project_video', start_time=41.2, interval=1/24, max_images=3):\n",
    "        screen, left_line, right_line = visualize_lanes_using_diagnostic_screen(img, left_line, right_line)\n",
    "\n",
    "        print(\"left_line.best_fit\", left_line.best_fit)\n",
    "        print(\"right_line.best_fit\", right_line.best_fit)\n",
    "\n",
    "        plt.figure(figsize=(20,12))\n",
    "        plt.imshow(screen)\n",
    "        plt.show()\n",
    "\n",
    "# UNCOMMENT TO RUN\n",
    "#demonstrate_lane_finding_on_video_frames_with_diag_screen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 7-17 Process the project video and save the results.\n",
    "\n",
    "left_line = None\n",
    "right_line = None\n",
    "\n",
    "def lane_line_diag(img):\n",
    "    global left_line, right_line\n",
    "    screen, left_line, right_line = visualize_lanes_using_diagnostic_screen(img, left_line, right_line)\n",
    "    return screen\n",
    "\n",
    "def writeout_lane_finding_video_with_diag_screen(src, dst, start=0, end=0):\n",
    "    clip = VideoFileClip(src).subclip(start, end)\n",
    "    diag_clip = clip.fl_image( lane_line_diag )\n",
    "    diag_clip.write_videofile(dst)\n",
    "\n",
    "# UNCOMMENT TO RUN\n",
    "#writeout_lane_finding_video_with_diag_screen('project_video.mp4', 'project_video_test.mp4', start=0, end=None)\n",
    "#writeout_lane_finding_video_with_diag_screen('challenge_video.mp4', 'challenge_video_test.mp4', start=0, end=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for processing the video in the final form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7-18 Define a function for composing a frame for the final video\n",
    "\n",
    "def compose_basicScreen(img, curverad=0, offset=0):\n",
    "\n",
    "    # Determine which side of center in English\n",
    "    if (offset <= 0):\n",
    "        side = 'left'\n",
    "    else:\n",
    "        side = 'right'\n",
    "    \n",
    "    # Make the offset a positive number now that we have the side\n",
    "    offset = abs(offset)\n",
    "        \n",
    "    # Use cv2 for drawing text in diagnostic pipeline.\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "    color = (255, 255, 255)\n",
    "    cv2.putText(img, 'Radius of curvature: {}m'.format(int(curverad)), (30, 50), font, 1, color, 1)\n",
    "    cv2.putText(img, 'Vehicle is {:.2f}m {} of center'.format(offset, side), (30, 90), font, 1, color, 1)\n",
    "\n",
    "    return img\n",
    "\n",
    "# optimization since y dimension doesn't change for our video\n",
    "g_ploty = np.linspace(0, 719, 720)\n",
    "\n",
    "def visualize_lane_using_basicScreen(img, left_line=None, right_line=None):\n",
    "    \n",
    "    img = cal_undistort(img)\n",
    "    binary_warped = get_birdseye_binary_warped(img, undistort=False)\n",
    "\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 80\n",
    "\n",
    "    if ((left_line == None) or (right_line == None)):\n",
    "        left_line, right_line, out_img = find_lane_lines(binary_warped, margin=margin, method='sliding_windows', produce_out_img=False)\n",
    "    else:\n",
    "        left_line, right_line, out_img = find_lane_lines(binary_warped, margin=margin, method='previous_fit', \n",
    "                                                         prev_left_line=left_line, prev_right_line=right_line, produce_out_img=False)\n",
    "\n",
    "    undistorted_overlayed = draw_lane_on_image(img, binary_warped, g_ploty, left_line.best_fitx, right_line.best_fitx)\n",
    "    \n",
    "    curverad = (left_line.radius_of_curvature_m + right_line.radius_of_curvature_m) / 2\n",
    "    \n",
    "    lane_center_px = get_lane_center_in_pixels(g_ploty, left_line.best_fit, right_line.best_fit)\n",
    "    lane_offset_m = get_lane_offset_in_meters(binary_warped.shape[1], lane_center_px)\n",
    "\n",
    "    screen = compose_basicScreen(undistorted_overlayed, curverad=curverad, offset=lane_offset_m)\n",
    "\n",
    "    return screen, left_line, right_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7-19 Process the project video and save the results.\n",
    "\n",
    "left_line = None\n",
    "right_line = None\n",
    "\n",
    "def lane_line_basic(img):\n",
    "    global left_line, right_line\n",
    "    screen, left_line, right_line = visualize_lane_using_basicScreen(img, left_line, right_line)\n",
    "    return screen\n",
    "\n",
    "def writeout_lane_finding_video_with_basicScreen(src, dst, start=0, end=0):\n",
    "    clip = VideoFileClip(src).subclip(start, end)\n",
    "    diag_clip = clip.fl_image( lane_line_basic )\n",
    "    diag_clip.write_videofile(dst)\n",
    "\n",
    "# UNCOMMENT TO RUN\n",
    "#writeout_lane_finding_video_with_basicScreen('project_video.mp4', 'project_video_basic.mp4', start=0, end=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_composite_2x3(img):\n",
    "    \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    #sv = np.divide(np.add(hsv[:,:,1], hsv[:,:,2]), 2).astype(np.uint8)\n",
    "    lsadd = np.add(hls[:,:,1], hls[:,:,2])\n",
    "    ls = np.uint8(255 * lsadd/np.max(lsadd))\n",
    "    \n",
    "    #svrgb = cv2.cvtColor(sv, cv2.COLOR_GRAY2RGB)\n",
    "    lsrgb = cv2.cvtColor(ls, cv2.COLOR_GRAY2RGB)\n",
    "    #lsrgb = to_RGB(ls)\n",
    "    \n",
    "    h, s, v = cv2.split(hsv)\n",
    "    h.fill(0)\n",
    "    #s.fill(0)\n",
    "    #v.fill(0)\n",
    "    hsv_test = cv2.merge([h, s, v])\n",
    "    hsv_test_rgb = cv2.cvtColor(hsv_test, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    #hsv0 = cv2.cvtColor(hsv[:,:,0], cv2.COLOR_GRAY2RGB)\n",
    "    hsv1 = cv2.cvtColor(hsv[:,:,1], cv2.COLOR_GRAY2RGB)\n",
    "    hsv2 = cv2.cvtColor(hsv[:,:,2], cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    #hls0 = cv2.cvtColor(hls[:,:,0], cv2.COLOR_GRAY2RGB)\n",
    "    hls1 = cv2.cvtColor(hls[:,:,1], cv2.COLOR_GRAY2RGB)\n",
    "    hls2 = cv2.cvtColor(hls[:,:,2], cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    return compose_2x3_screen(diag1=hsv_test_rgb, diag2=hsv1, diag3=hsv2, \n",
    "                              diag4=lsrgb, diag5=hls1, diag6=hls2, \n",
    "                              title1=\"svrgb\", title2=\"S\", title3=\"V\", \n",
    "                              title4=\"lsrgb\", title5=\"L\", title6=\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def demonstrate_composite_2x3_screen():\n",
    "\n",
    "    for img in extract_frames('project_video', start_time=41.2, interval=1/24, max_images=1):\n",
    "\n",
    "        screen = visualize_composite_2x3(img)\n",
    "\n",
    "        plt.figure(figsize=(20,12))\n",
    "        plt.imshow(screen)\n",
    "        plt.show()\n",
    "\n",
    "# UNCOMMENT TO RUN\n",
    "demonstrate_composite_2x3_screen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeout_hsv_hls_comparison_video(src, dst, start=0, end=0):\n",
    "    clip = VideoFileClip(src).subclip(start, end)\n",
    "    diag_clip = clip.fl_image( composite_2x3 )\n",
    "    diag_clip.write_videofile(dst)\n",
    "\n",
    "# UNCOMMENT TO RUN\n",
    "#writeout_hsv_hls_comparison_video('project_video.mp4', 'project_video_hsv_hls.mp4', start=0, end=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {
    "29559dfdfee34ce88b621c536551b29a": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
